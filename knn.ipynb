{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a6d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import eye\n",
    "from scipy.sparse.linalg import inv\n",
    "\n",
    "from ipynb.fs.full.roc_curve import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a8e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd. set_option('display.max_rows', 10) # or 1000.\n",
    "pd.options.display.max_colwidth = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e26f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df = pd.read_excel('features_30_9_healthy.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9dc719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df['class'] = 0  # negative\n",
    "healthy_df.rename(columns={32: 'file_name', 31: 32}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f9a8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>32</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.58207</td>\n",
       "      <td>0.84332</td>\n",
       "      <td>1.85755</td>\n",
       "      <td>0.75574</td>\n",
       "      <td>9.51179</td>\n",
       "      <td>6.68282</td>\n",
       "      <td>3.31333</td>\n",
       "      <td>3.98427</td>\n",
       "      <td>0.32795</td>\n",
       "      <td>...</td>\n",
       "      <td>4539.14893</td>\n",
       "      <td>9787</td>\n",
       "      <td>12757</td>\n",
       "      <td>5068</td>\n",
       "      <td>7689</td>\n",
       "      <td>1721357.125</td>\n",
       "      <td>1312.00500</td>\n",
       "      <td>1</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06342</td>\n",
       "      <td>0.96902</td>\n",
       "      <td>0.74959</td>\n",
       "      <td>1.93489</td>\n",
       "      <td>0.67394</td>\n",
       "      <td>6.65879</td>\n",
       "      <td>6.44094</td>\n",
       "      <td>3.35085</td>\n",
       "      <td>4.40313</td>\n",
       "      <td>0.47218</td>\n",
       "      <td>...</td>\n",
       "      <td>2038.07898</td>\n",
       "      <td>10136</td>\n",
       "      <td>12932</td>\n",
       "      <td>8039</td>\n",
       "      <td>4893</td>\n",
       "      <td>702499.750</td>\n",
       "      <td>838.15259</td>\n",
       "      <td>1</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10062</td>\n",
       "      <td>0.68576</td>\n",
       "      <td>0.79684</td>\n",
       "      <td>1.68772</td>\n",
       "      <td>0.73787</td>\n",
       "      <td>9.50464</td>\n",
       "      <td>6.04032</td>\n",
       "      <td>3.17706</td>\n",
       "      <td>3.93885</td>\n",
       "      <td>0.38197</td>\n",
       "      <td>...</td>\n",
       "      <td>4157.31250</td>\n",
       "      <td>9961</td>\n",
       "      <td>12583</td>\n",
       "      <td>5592</td>\n",
       "      <td>6991</td>\n",
       "      <td>1237559.375</td>\n",
       "      <td>1112.45642</td>\n",
       "      <td>1</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.74973</td>\n",
       "      <td>0.87516</td>\n",
       "      <td>3.00270</td>\n",
       "      <td>0.71925</td>\n",
       "      <td>7.70397</td>\n",
       "      <td>10.57323</td>\n",
       "      <td>3.66807</td>\n",
       "      <td>4.57908</td>\n",
       "      <td>0.39824</td>\n",
       "      <td>...</td>\n",
       "      <td>3706.43335</td>\n",
       "      <td>8388</td>\n",
       "      <td>12233</td>\n",
       "      <td>4544</td>\n",
       "      <td>7689</td>\n",
       "      <td>2748470.500</td>\n",
       "      <td>1657.85120</td>\n",
       "      <td>1</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07776</td>\n",
       "      <td>0.70084</td>\n",
       "      <td>0.85559</td>\n",
       "      <td>2.42659</td>\n",
       "      <td>0.73281</td>\n",
       "      <td>8.71716</td>\n",
       "      <td>8.64065</td>\n",
       "      <td>3.42859</td>\n",
       "      <td>4.24003</td>\n",
       "      <td>0.38487</td>\n",
       "      <td>...</td>\n",
       "      <td>4775.73877</td>\n",
       "      <td>9088</td>\n",
       "      <td>12583</td>\n",
       "      <td>3845</td>\n",
       "      <td>8738</td>\n",
       "      <td>2867137.750</td>\n",
       "      <td>1693.26245</td>\n",
       "      <td>1</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.06155</td>\n",
       "      <td>0.69752</td>\n",
       "      <td>0.89054</td>\n",
       "      <td>3.18606</td>\n",
       "      <td>0.74120</td>\n",
       "      <td>7.02580</td>\n",
       "      <td>11.77003</td>\n",
       "      <td>3.62602</td>\n",
       "      <td>4.42574</td>\n",
       "      <td>0.39767</td>\n",
       "      <td>...</td>\n",
       "      <td>3821.18237</td>\n",
       "      <td>5915</td>\n",
       "      <td>10883</td>\n",
       "      <td>2129</td>\n",
       "      <td>8754</td>\n",
       "      <td>3848079.250</td>\n",
       "      <td>1961.65222</td>\n",
       "      <td>1</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.06068</td>\n",
       "      <td>0.75961</td>\n",
       "      <td>0.86736</td>\n",
       "      <td>2.86349</td>\n",
       "      <td>0.71831</td>\n",
       "      <td>7.67092</td>\n",
       "      <td>10.40712</td>\n",
       "      <td>3.60249</td>\n",
       "      <td>4.47293</td>\n",
       "      <td>0.40430</td>\n",
       "      <td>...</td>\n",
       "      <td>4307.60449</td>\n",
       "      <td>5678</td>\n",
       "      <td>10646</td>\n",
       "      <td>1656</td>\n",
       "      <td>8990</td>\n",
       "      <td>3530869.500</td>\n",
       "      <td>1879.06079</td>\n",
       "      <td>1</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.70322</td>\n",
       "      <td>0.85896</td>\n",
       "      <td>2.49303</td>\n",
       "      <td>0.74774</td>\n",
       "      <td>6.01145</td>\n",
       "      <td>9.14703</td>\n",
       "      <td>3.34126</td>\n",
       "      <td>4.10024</td>\n",
       "      <td>0.41432</td>\n",
       "      <td>...</td>\n",
       "      <td>3502.35352</td>\n",
       "      <td>4495</td>\n",
       "      <td>10646</td>\n",
       "      <td>1420</td>\n",
       "      <td>9226</td>\n",
       "      <td>3042845.750</td>\n",
       "      <td>1744.37549</td>\n",
       "      <td>1</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.12647</td>\n",
       "      <td>0.66081</td>\n",
       "      <td>0.88106</td>\n",
       "      <td>2.77796</td>\n",
       "      <td>0.75613</td>\n",
       "      <td>5.16639</td>\n",
       "      <td>10.15986</td>\n",
       "      <td>3.13970</td>\n",
       "      <td>3.91218</td>\n",
       "      <td>0.39423</td>\n",
       "      <td>...</td>\n",
       "      <td>2767.90771</td>\n",
       "      <td>4022</td>\n",
       "      <td>10410</td>\n",
       "      <td>1656</td>\n",
       "      <td>8754</td>\n",
       "      <td>3174905.250</td>\n",
       "      <td>1781.82642</td>\n",
       "      <td>1</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.12322</td>\n",
       "      <td>0.65647</td>\n",
       "      <td>0.87699</td>\n",
       "      <td>2.66837</td>\n",
       "      <td>0.76188</td>\n",
       "      <td>6.34509</td>\n",
       "      <td>9.91083</td>\n",
       "      <td>3.27109</td>\n",
       "      <td>3.97261</td>\n",
       "      <td>0.40030</td>\n",
       "      <td>...</td>\n",
       "      <td>4565.53125</td>\n",
       "      <td>4259</td>\n",
       "      <td>12066</td>\n",
       "      <td>473</td>\n",
       "      <td>11593</td>\n",
       "      <td>5180411.500</td>\n",
       "      <td>2276.05176</td>\n",
       "      <td>1</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2108 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4        5         6        7  \\\n",
       "0     0.09242  0.58207  0.84332  1.85755  0.75574  9.51179   6.68282  3.31333   \n",
       "1     0.06342  0.96902  0.74959  1.93489  0.67394  6.65879   6.44094  3.35085   \n",
       "2     0.10062  0.68576  0.79684  1.68772  0.73787  9.50464   6.04032  3.17706   \n",
       "3     0.05449  0.74973  0.87516  3.00270  0.71925  7.70397  10.57323  3.66807   \n",
       "4     0.07776  0.70084  0.85559  2.42659  0.73281  8.71716   8.64065  3.42859   \n",
       "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
       "2103  0.06155  0.69752  0.89054  3.18606  0.74120  7.02580  11.77003  3.62602   \n",
       "2104  0.06068  0.75961  0.86736  2.86349  0.71831  7.67092  10.40712  3.60249   \n",
       "2105  0.09644  0.70322  0.85896  2.49303  0.74774  6.01145   9.14703  3.34126   \n",
       "2106  0.12647  0.66081  0.88106  2.77796  0.75613  5.16639  10.15986  3.13970   \n",
       "2107  0.12322  0.65647  0.87699  2.66837  0.76188  6.34509   9.91083  3.27109   \n",
       "\n",
       "            8        9  ...          24     25     26    27     28  \\\n",
       "0     3.98427  0.32795  ...  4539.14893   9787  12757  5068   7689   \n",
       "1     4.40313  0.47218  ...  2038.07898  10136  12932  8039   4893   \n",
       "2     3.93885  0.38197  ...  4157.31250   9961  12583  5592   6991   \n",
       "3     4.57908  0.39824  ...  3706.43335   8388  12233  4544   7689   \n",
       "4     4.24003  0.38487  ...  4775.73877   9088  12583  3845   8738   \n",
       "...       ...      ...  ...         ...    ...    ...   ...    ...   \n",
       "2103  4.42574  0.39767  ...  3821.18237   5915  10883  2129   8754   \n",
       "2104  4.47293  0.40430  ...  4307.60449   5678  10646  1656   8990   \n",
       "2105  4.10024  0.41432  ...  3502.35352   4495  10646  1420   9226   \n",
       "2106  3.91218  0.39423  ...  2767.90771   4022  10410  1656   8754   \n",
       "2107  3.97261  0.40030  ...  4565.53125   4259  12066   473  11593   \n",
       "\n",
       "               29          30  32  \\\n",
       "0     1721357.125  1312.00500   1   \n",
       "1      702499.750   838.15259   1   \n",
       "2     1237559.375  1112.45642   1   \n",
       "3     2748470.500  1657.85120   1   \n",
       "4     2867137.750  1693.26245   1   \n",
       "...           ...         ...  ..   \n",
       "2103  3848079.250  1961.65222   1   \n",
       "2104  3530869.500  1879.06079   1   \n",
       "2105  3042845.750  1744.37549   1   \n",
       "2106  3174905.250  1781.82642   1   \n",
       "2107  5180411.500  2276.05176   1   \n",
       "\n",
       "                                                                                                   file_name  \\\n",
       "0     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "1     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "2     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "3     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "4     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "...                                                                                                      ...   \n",
       "2103  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2104  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2105  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2106  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2107  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "\n",
       "      class  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2103      0  \n",
       "2104      0  \n",
       "2105      0  \n",
       "2106      0  \n",
       "2107      0  \n",
       "\n",
       "[2108 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e9def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_df = pd.read_excel('features_30_9_insult.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70444ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_df['class'] = 1\n",
    "insult_df.rename(columns={33: 'file_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9dce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.75858</td>\n",
       "      <td>0.85508</td>\n",
       "      <td>2.61725</td>\n",
       "      <td>0.71279</td>\n",
       "      <td>9.07447</td>\n",
       "      <td>9.53269</td>\n",
       "      <td>3.54796</td>\n",
       "      <td>4.38729</td>\n",
       "      <td>0.39242</td>\n",
       "      <td>...</td>\n",
       "      <td>7689</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1706812.750</td>\n",
       "      <td>1306.45044</td>\n",
       "      <td>0.09679</td>\n",
       "      <td>0.44111</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05805</td>\n",
       "      <td>0.80593</td>\n",
       "      <td>0.86047</td>\n",
       "      <td>2.88797</td>\n",
       "      <td>0.70327</td>\n",
       "      <td>8.43171</td>\n",
       "      <td>10.18995</td>\n",
       "      <td>3.56138</td>\n",
       "      <td>4.49190</td>\n",
       "      <td>0.41046</td>\n",
       "      <td>...</td>\n",
       "      <td>7340</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1868834.875</td>\n",
       "      <td>1367.05334</td>\n",
       "      <td>0.14702</td>\n",
       "      <td>0.57444</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.80487</td>\n",
       "      <td>0.86085</td>\n",
       "      <td>2.89208</td>\n",
       "      <td>0.69992</td>\n",
       "      <td>8.27271</td>\n",
       "      <td>10.48810</td>\n",
       "      <td>3.61427</td>\n",
       "      <td>4.52479</td>\n",
       "      <td>0.40255</td>\n",
       "      <td>...</td>\n",
       "      <td>6990</td>\n",
       "      <td>10311</td>\n",
       "      <td>3845</td>\n",
       "      <td>6466</td>\n",
       "      <td>1798897.125</td>\n",
       "      <td>1341.22974</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.60778</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07138</td>\n",
       "      <td>0.60490</td>\n",
       "      <td>0.87878</td>\n",
       "      <td>2.49509</td>\n",
       "      <td>0.74577</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>9.16320</td>\n",
       "      <td>3.48943</td>\n",
       "      <td>4.20273</td>\n",
       "      <td>0.32976</td>\n",
       "      <td>...</td>\n",
       "      <td>7340</td>\n",
       "      <td>11884</td>\n",
       "      <td>3845</td>\n",
       "      <td>8039</td>\n",
       "      <td>2424746.750</td>\n",
       "      <td>1557.15979</td>\n",
       "      <td>0.24542</td>\n",
       "      <td>0.55333</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06371</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.88761</td>\n",
       "      <td>2.71714</td>\n",
       "      <td>0.74178</td>\n",
       "      <td>8.10054</td>\n",
       "      <td>9.98028</td>\n",
       "      <td>3.60307</td>\n",
       "      <td>4.32808</td>\n",
       "      <td>0.32754</td>\n",
       "      <td>...</td>\n",
       "      <td>8214</td>\n",
       "      <td>12058</td>\n",
       "      <td>3845</td>\n",
       "      <td>8213</td>\n",
       "      <td>2890672.500</td>\n",
       "      <td>1700.19775</td>\n",
       "      <td>0.29329</td>\n",
       "      <td>0.48111</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.06646</td>\n",
       "      <td>0.65228</td>\n",
       "      <td>0.89100</td>\n",
       "      <td>2.99205</td>\n",
       "      <td>0.75269</td>\n",
       "      <td>8.06304</td>\n",
       "      <td>10.62932</td>\n",
       "      <td>3.63314</td>\n",
       "      <td>4.42857</td>\n",
       "      <td>0.38109</td>\n",
       "      <td>...</td>\n",
       "      <td>6861</td>\n",
       "      <td>11120</td>\n",
       "      <td>2129</td>\n",
       "      <td>8991</td>\n",
       "      <td>3640547.750</td>\n",
       "      <td>1908.02197</td>\n",
       "      <td>0.55711</td>\n",
       "      <td>0.62222</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.06672</td>\n",
       "      <td>0.58668</td>\n",
       "      <td>0.89720</td>\n",
       "      <td>2.85336</td>\n",
       "      <td>0.75804</td>\n",
       "      <td>8.28487</td>\n",
       "      <td>10.18638</td>\n",
       "      <td>3.62216</td>\n",
       "      <td>4.34481</td>\n",
       "      <td>0.33563</td>\n",
       "      <td>...</td>\n",
       "      <td>6861</td>\n",
       "      <td>11120</td>\n",
       "      <td>1893</td>\n",
       "      <td>9227</td>\n",
       "      <td>3537324.750</td>\n",
       "      <td>1880.77771</td>\n",
       "      <td>0.45430</td>\n",
       "      <td>0.67111</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.07679</td>\n",
       "      <td>0.60400</td>\n",
       "      <td>0.87018</td>\n",
       "      <td>2.32624</td>\n",
       "      <td>0.75293</td>\n",
       "      <td>8.35847</td>\n",
       "      <td>8.05221</td>\n",
       "      <td>3.45328</td>\n",
       "      <td>4.18973</td>\n",
       "      <td>0.34140</td>\n",
       "      <td>...</td>\n",
       "      <td>6861</td>\n",
       "      <td>11120</td>\n",
       "      <td>1893</td>\n",
       "      <td>9227</td>\n",
       "      <td>2920900.750</td>\n",
       "      <td>1709.06421</td>\n",
       "      <td>0.34919</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.07262</td>\n",
       "      <td>0.62511</td>\n",
       "      <td>0.87357</td>\n",
       "      <td>2.47208</td>\n",
       "      <td>0.74652</td>\n",
       "      <td>8.93944</td>\n",
       "      <td>8.51236</td>\n",
       "      <td>3.49029</td>\n",
       "      <td>4.25676</td>\n",
       "      <td>0.34790</td>\n",
       "      <td>...</td>\n",
       "      <td>7098</td>\n",
       "      <td>11120</td>\n",
       "      <td>1893</td>\n",
       "      <td>9227</td>\n",
       "      <td>3107574.750</td>\n",
       "      <td>1762.83142</td>\n",
       "      <td>0.24275</td>\n",
       "      <td>0.63889</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.06230</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.89006</td>\n",
       "      <td>3.15996</td>\n",
       "      <td>0.73572</td>\n",
       "      <td>8.59569</td>\n",
       "      <td>11.16692</td>\n",
       "      <td>3.61403</td>\n",
       "      <td>4.44903</td>\n",
       "      <td>0.38554</td>\n",
       "      <td>...</td>\n",
       "      <td>7098</td>\n",
       "      <td>11120</td>\n",
       "      <td>1893</td>\n",
       "      <td>9227</td>\n",
       "      <td>4060280.250</td>\n",
       "      <td>2015.01367</td>\n",
       "      <td>0.13546</td>\n",
       "      <td>0.47444</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4        5         6        7  \\\n",
       "0     0.06081  0.75858  0.85508  2.61725  0.71279  9.07447   9.53269  3.54796   \n",
       "1     0.05805  0.80593  0.86047  2.88797  0.70327  8.43171  10.18995  3.56138   \n",
       "2     0.05735  0.80487  0.86085  2.89208  0.69992  8.27271  10.48810  3.61427   \n",
       "3     0.07138  0.60490  0.87878  2.49509  0.74577  7.20000   9.16320  3.48943   \n",
       "4     0.06371  0.61074  0.88761  2.71714  0.74178  8.10054   9.98028  3.60307   \n",
       "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
       "5930  0.06646  0.65228  0.89100  2.99205  0.75269  8.06304  10.62932  3.63314   \n",
       "5931  0.06672  0.58668  0.89720  2.85336  0.75804  8.28487  10.18638  3.62216   \n",
       "5932  0.07679  0.60400  0.87018  2.32624  0.75293  8.35847   8.05221  3.45328   \n",
       "5933  0.07262  0.62511  0.87357  2.47208  0.74652  8.93944   8.51236  3.49029   \n",
       "5934  0.06230  0.69481  0.89006  3.15996  0.73572  8.59569  11.16692  3.61403   \n",
       "\n",
       "            8        9  ...    25     26    27    28           29          30  \\\n",
       "0     4.38729  0.39242  ...  7689  10486  4019  6467  1706812.750  1306.45044   \n",
       "1     4.49190  0.41046  ...  7340  10486  4019  6467  1868834.875  1367.05334   \n",
       "2     4.52479  0.40255  ...  6990  10311  3845  6466  1798897.125  1341.22974   \n",
       "3     4.20273  0.32976  ...  7340  11884  3845  8039  2424746.750  1557.15979   \n",
       "4     4.32808  0.32754  ...  8214  12058  3845  8213  2890672.500  1700.19775   \n",
       "...       ...      ...  ...   ...    ...   ...   ...          ...         ...   \n",
       "5930  4.42857  0.38109  ...  6861  11120  2129  8991  3640547.750  1908.02197   \n",
       "5931  4.34481  0.33563  ...  6861  11120  1893  9227  3537324.750  1880.77771   \n",
       "5932  4.18973  0.34140  ...  6861  11120  1893  9227  2920900.750  1709.06421   \n",
       "5933  4.25676  0.34790  ...  7098  11120  1893  9227  3107574.750  1762.83142   \n",
       "5934  4.44903  0.38554  ...  7098  11120  1893  9227  4060280.250  2015.01367   \n",
       "\n",
       "           31       32  \\\n",
       "0     0.09679  0.44111   \n",
       "1     0.14702  0.57444   \n",
       "2     0.19660  0.60778   \n",
       "3     0.24542  0.55333   \n",
       "4     0.29329  0.48111   \n",
       "...       ...      ...   \n",
       "5930  0.55711  0.62222   \n",
       "5931  0.45430  0.67111   \n",
       "5932  0.34919  0.69000   \n",
       "5933  0.24275  0.63889   \n",
       "5934  0.13546  0.47444   \n",
       "\n",
       "                                                                                                   file_name  \\\n",
       "0     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "1     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "2     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "3     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "4     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "...                                                                                                      ...   \n",
       "5930  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "5931  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "5932  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "5933  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "5934  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "\n",
       "      class  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "5930      1  \n",
       "5931      1  \n",
       "5932      1  \n",
       "5933      1  \n",
       "5934      1  \n",
       "\n",
       "[5935 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insult_df  # positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5cf0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([insult_df, healthy_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259db239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = df['file_name']\n",
    "unique_file_names = file_names.unique()  # unique file names in df\n",
    "df.sort_values(by=['file_name', 'class'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9604e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = df['file_name']  # all file names of healthy_df\n",
    "unique_file_names = file_names.unique()  # unique file names of healthy_df\n",
    "df['files_indices'] = file_names.factorize()[0]  # index of unique file names\n",
    "files_indices_list = df['files_indices']\n",
    "n_files = len(unique_file_names)  # number of unique files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abba5fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>files_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.75858</td>\n",
       "      <td>0.85508</td>\n",
       "      <td>2.61725</td>\n",
       "      <td>0.71279</td>\n",
       "      <td>9.07447</td>\n",
       "      <td>9.53269</td>\n",
       "      <td>3.54796</td>\n",
       "      <td>4.38729</td>\n",
       "      <td>0.39242</td>\n",
       "      <td>...</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1706812.750</td>\n",
       "      <td>1306.45044</td>\n",
       "      <td>0.09679</td>\n",
       "      <td>0.44111</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05805</td>\n",
       "      <td>0.80593</td>\n",
       "      <td>0.86047</td>\n",
       "      <td>2.88797</td>\n",
       "      <td>0.70327</td>\n",
       "      <td>8.43171</td>\n",
       "      <td>10.18995</td>\n",
       "      <td>3.56138</td>\n",
       "      <td>4.49190</td>\n",
       "      <td>0.41046</td>\n",
       "      <td>...</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1868834.875</td>\n",
       "      <td>1367.05334</td>\n",
       "      <td>0.14702</td>\n",
       "      <td>0.57444</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.80487</td>\n",
       "      <td>0.86085</td>\n",
       "      <td>2.89208</td>\n",
       "      <td>0.69992</td>\n",
       "      <td>8.27271</td>\n",
       "      <td>10.48810</td>\n",
       "      <td>3.61427</td>\n",
       "      <td>4.52479</td>\n",
       "      <td>0.40255</td>\n",
       "      <td>...</td>\n",
       "      <td>10311</td>\n",
       "      <td>3845</td>\n",
       "      <td>6466</td>\n",
       "      <td>1798897.125</td>\n",
       "      <td>1341.22974</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.60778</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07138</td>\n",
       "      <td>0.60490</td>\n",
       "      <td>0.87878</td>\n",
       "      <td>2.49509</td>\n",
       "      <td>0.74577</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>9.16320</td>\n",
       "      <td>3.48943</td>\n",
       "      <td>4.20273</td>\n",
       "      <td>0.32976</td>\n",
       "      <td>...</td>\n",
       "      <td>11884</td>\n",
       "      <td>3845</td>\n",
       "      <td>8039</td>\n",
       "      <td>2424746.750</td>\n",
       "      <td>1557.15979</td>\n",
       "      <td>0.24542</td>\n",
       "      <td>0.55333</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06371</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.88761</td>\n",
       "      <td>2.71714</td>\n",
       "      <td>0.74178</td>\n",
       "      <td>8.10054</td>\n",
       "      <td>9.98028</td>\n",
       "      <td>3.60307</td>\n",
       "      <td>4.32808</td>\n",
       "      <td>0.32754</td>\n",
       "      <td>...</td>\n",
       "      <td>12058</td>\n",
       "      <td>3845</td>\n",
       "      <td>8213</td>\n",
       "      <td>2890672.500</td>\n",
       "      <td>1700.19775</td>\n",
       "      <td>0.29329</td>\n",
       "      <td>0.48111</td>\n",
       "      <td>AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.06155</td>\n",
       "      <td>0.69752</td>\n",
       "      <td>0.89054</td>\n",
       "      <td>3.18606</td>\n",
       "      <td>0.74120</td>\n",
       "      <td>7.02580</td>\n",
       "      <td>11.77003</td>\n",
       "      <td>3.62602</td>\n",
       "      <td>4.42574</td>\n",
       "      <td>0.39767</td>\n",
       "      <td>...</td>\n",
       "      <td>10883</td>\n",
       "      <td>2129</td>\n",
       "      <td>8754</td>\n",
       "      <td>3848079.250</td>\n",
       "      <td>1961.65222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.06068</td>\n",
       "      <td>0.75961</td>\n",
       "      <td>0.86736</td>\n",
       "      <td>2.86349</td>\n",
       "      <td>0.71831</td>\n",
       "      <td>7.67092</td>\n",
       "      <td>10.40712</td>\n",
       "      <td>3.60249</td>\n",
       "      <td>4.47293</td>\n",
       "      <td>0.40430</td>\n",
       "      <td>...</td>\n",
       "      <td>10646</td>\n",
       "      <td>1656</td>\n",
       "      <td>8990</td>\n",
       "      <td>3530869.500</td>\n",
       "      <td>1879.06079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.70322</td>\n",
       "      <td>0.85896</td>\n",
       "      <td>2.49303</td>\n",
       "      <td>0.74774</td>\n",
       "      <td>6.01145</td>\n",
       "      <td>9.14703</td>\n",
       "      <td>3.34126</td>\n",
       "      <td>4.10024</td>\n",
       "      <td>0.41432</td>\n",
       "      <td>...</td>\n",
       "      <td>10646</td>\n",
       "      <td>1420</td>\n",
       "      <td>9226</td>\n",
       "      <td>3042845.750</td>\n",
       "      <td>1744.37549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.12647</td>\n",
       "      <td>0.66081</td>\n",
       "      <td>0.88106</td>\n",
       "      <td>2.77796</td>\n",
       "      <td>0.75613</td>\n",
       "      <td>5.16639</td>\n",
       "      <td>10.15986</td>\n",
       "      <td>3.13970</td>\n",
       "      <td>3.91218</td>\n",
       "      <td>0.39423</td>\n",
       "      <td>...</td>\n",
       "      <td>10410</td>\n",
       "      <td>1656</td>\n",
       "      <td>8754</td>\n",
       "      <td>3174905.250</td>\n",
       "      <td>1781.82642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.12322</td>\n",
       "      <td>0.65647</td>\n",
       "      <td>0.87699</td>\n",
       "      <td>2.66837</td>\n",
       "      <td>0.76188</td>\n",
       "      <td>6.34509</td>\n",
       "      <td>9.91083</td>\n",
       "      <td>3.27109</td>\n",
       "      <td>3.97261</td>\n",
       "      <td>0.40030</td>\n",
       "      <td>...</td>\n",
       "      <td>12066</td>\n",
       "      <td>473</td>\n",
       "      <td>11593</td>\n",
       "      <td>5180411.500</td>\n",
       "      <td>2276.05176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8043 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4        5         6        7  \\\n",
       "0     0.06081  0.75858  0.85508  2.61725  0.71279  9.07447   9.53269  3.54796   \n",
       "1     0.05805  0.80593  0.86047  2.88797  0.70327  8.43171  10.18995  3.56138   \n",
       "2     0.05735  0.80487  0.86085  2.89208  0.69992  8.27271  10.48810  3.61427   \n",
       "3     0.07138  0.60490  0.87878  2.49509  0.74577  7.20000   9.16320  3.48943   \n",
       "4     0.06371  0.61074  0.88761  2.71714  0.74178  8.10054   9.98028  3.60307   \n",
       "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
       "2103  0.06155  0.69752  0.89054  3.18606  0.74120  7.02580  11.77003  3.62602   \n",
       "2104  0.06068  0.75961  0.86736  2.86349  0.71831  7.67092  10.40712  3.60249   \n",
       "2105  0.09644  0.70322  0.85896  2.49303  0.74774  6.01145   9.14703  3.34126   \n",
       "2106  0.12647  0.66081  0.88106  2.77796  0.75613  5.16639  10.15986  3.13970   \n",
       "2107  0.12322  0.65647  0.87699  2.66837  0.76188  6.34509   9.91083  3.27109   \n",
       "\n",
       "            8        9  ...     26    27     28           29          30  \\\n",
       "0     4.38729  0.39242  ...  10486  4019   6467  1706812.750  1306.45044   \n",
       "1     4.49190  0.41046  ...  10486  4019   6467  1868834.875  1367.05334   \n",
       "2     4.52479  0.40255  ...  10311  3845   6466  1798897.125  1341.22974   \n",
       "3     4.20273  0.32976  ...  11884  3845   8039  2424746.750  1557.15979   \n",
       "4     4.32808  0.32754  ...  12058  3845   8213  2890672.500  1700.19775   \n",
       "...       ...      ...  ...    ...   ...    ...          ...         ...   \n",
       "2103  4.42574  0.39767  ...  10883  2129   8754  3848079.250  1961.65222   \n",
       "2104  4.47293  0.40430  ...  10646  1656   8990  3530869.500  1879.06079   \n",
       "2105  4.10024  0.41432  ...  10646  1420   9226  3042845.750  1744.37549   \n",
       "2106  3.91218  0.39423  ...  10410  1656   8754  3174905.250  1781.82642   \n",
       "2107  3.97261  0.40030  ...  12066   473  11593  5180411.500  2276.05176   \n",
       "\n",
       "           31       32  \\\n",
       "0     0.09679  0.44111   \n",
       "1     0.14702  0.57444   \n",
       "2     0.19660  0.60778   \n",
       "3     0.24542  0.55333   \n",
       "4     0.29329  0.48111   \n",
       "...       ...      ...   \n",
       "2103      NaN  1.00000   \n",
       "2104      NaN  1.00000   \n",
       "2105      NaN  1.00000   \n",
       "2106      NaN  1.00000   \n",
       "2107      NaN  1.00000   \n",
       "\n",
       "                                                                                                   file_name  \\\n",
       "0     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "1     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "2     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "3     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "4     AAL09091956__20181106__12038__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.5520.1541473094.3434_198   \n",
       "...                                                                                                      ...   \n",
       "2103  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2104  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2105  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2106  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2107  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "\n",
       "      class  files_indices  \n",
       "0         1              0  \n",
       "1         1              0  \n",
       "2         1              0  \n",
       "3         1              0  \n",
       "4         1              0  \n",
       "...     ...            ...  \n",
       "2103      0             45  \n",
       "2104      0             45  \n",
       "2105      0             45  \n",
       "2106      0             45  \n",
       "2107      0             45  \n",
       "\n",
       "[8043 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf57138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df.iloc[:,:31]  # healthy_df feautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b32c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.75858</td>\n",
       "      <td>0.85508</td>\n",
       "      <td>2.61725</td>\n",
       "      <td>0.71279</td>\n",
       "      <td>9.07447</td>\n",
       "      <td>9.53269</td>\n",
       "      <td>3.54796</td>\n",
       "      <td>4.38729</td>\n",
       "      <td>0.39242</td>\n",
       "      <td>...</td>\n",
       "      <td>60.42937</td>\n",
       "      <td>0.03730</td>\n",
       "      <td>4.83596</td>\n",
       "      <td>3644.60889</td>\n",
       "      <td>7689</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1706812.750</td>\n",
       "      <td>1306.45044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05805</td>\n",
       "      <td>0.80593</td>\n",
       "      <td>0.86047</td>\n",
       "      <td>2.88797</td>\n",
       "      <td>0.70327</td>\n",
       "      <td>8.43171</td>\n",
       "      <td>10.18995</td>\n",
       "      <td>3.56138</td>\n",
       "      <td>4.49190</td>\n",
       "      <td>0.41046</td>\n",
       "      <td>...</td>\n",
       "      <td>38.84860</td>\n",
       "      <td>0.03628</td>\n",
       "      <td>4.89183</td>\n",
       "      <td>3413.93018</td>\n",
       "      <td>7340</td>\n",
       "      <td>10486</td>\n",
       "      <td>4019</td>\n",
       "      <td>6467</td>\n",
       "      <td>1868834.875</td>\n",
       "      <td>1367.05334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.80487</td>\n",
       "      <td>0.86085</td>\n",
       "      <td>2.89208</td>\n",
       "      <td>0.69992</td>\n",
       "      <td>8.27271</td>\n",
       "      <td>10.48810</td>\n",
       "      <td>3.61427</td>\n",
       "      <td>4.52479</td>\n",
       "      <td>0.40255</td>\n",
       "      <td>...</td>\n",
       "      <td>36.57544</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>4.85308</td>\n",
       "      <td>3305.78662</td>\n",
       "      <td>6990</td>\n",
       "      <td>10311</td>\n",
       "      <td>3845</td>\n",
       "      <td>6466</td>\n",
       "      <td>1798897.125</td>\n",
       "      <td>1341.22974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07138</td>\n",
       "      <td>0.60490</td>\n",
       "      <td>0.87878</td>\n",
       "      <td>2.49509</td>\n",
       "      <td>0.74577</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>9.16320</td>\n",
       "      <td>3.48943</td>\n",
       "      <td>4.20273</td>\n",
       "      <td>0.32976</td>\n",
       "      <td>...</td>\n",
       "      <td>28.97285</td>\n",
       "      <td>0.03326</td>\n",
       "      <td>5.07144</td>\n",
       "      <td>3614.73560</td>\n",
       "      <td>7340</td>\n",
       "      <td>11884</td>\n",
       "      <td>3845</td>\n",
       "      <td>8039</td>\n",
       "      <td>2424746.750</td>\n",
       "      <td>1557.15979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06371</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.88761</td>\n",
       "      <td>2.71714</td>\n",
       "      <td>0.74178</td>\n",
       "      <td>8.10054</td>\n",
       "      <td>9.98028</td>\n",
       "      <td>3.60307</td>\n",
       "      <td>4.32808</td>\n",
       "      <td>0.32754</td>\n",
       "      <td>...</td>\n",
       "      <td>35.43299</td>\n",
       "      <td>0.02961</td>\n",
       "      <td>5.22304</td>\n",
       "      <td>4149.30322</td>\n",
       "      <td>8214</td>\n",
       "      <td>12058</td>\n",
       "      <td>3845</td>\n",
       "      <td>8213</td>\n",
       "      <td>2890672.500</td>\n",
       "      <td>1700.19775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.06155</td>\n",
       "      <td>0.69752</td>\n",
       "      <td>0.89054</td>\n",
       "      <td>3.18606</td>\n",
       "      <td>0.74120</td>\n",
       "      <td>7.02580</td>\n",
       "      <td>11.77003</td>\n",
       "      <td>3.62602</td>\n",
       "      <td>4.42574</td>\n",
       "      <td>0.39767</td>\n",
       "      <td>...</td>\n",
       "      <td>14.36549</td>\n",
       "      <td>0.03582</td>\n",
       "      <td>4.90722</td>\n",
       "      <td>3821.18237</td>\n",
       "      <td>5915</td>\n",
       "      <td>10883</td>\n",
       "      <td>2129</td>\n",
       "      <td>8754</td>\n",
       "      <td>3848079.250</td>\n",
       "      <td>1961.65222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.06068</td>\n",
       "      <td>0.75961</td>\n",
       "      <td>0.86736</td>\n",
       "      <td>2.86349</td>\n",
       "      <td>0.71831</td>\n",
       "      <td>7.67092</td>\n",
       "      <td>10.40712</td>\n",
       "      <td>3.60249</td>\n",
       "      <td>4.47293</td>\n",
       "      <td>0.40430</td>\n",
       "      <td>...</td>\n",
       "      <td>27.55488</td>\n",
       "      <td>0.03788</td>\n",
       "      <td>4.86279</td>\n",
       "      <td>4307.60449</td>\n",
       "      <td>5678</td>\n",
       "      <td>10646</td>\n",
       "      <td>1656</td>\n",
       "      <td>8990</td>\n",
       "      <td>3530869.500</td>\n",
       "      <td>1879.06079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.70322</td>\n",
       "      <td>0.85896</td>\n",
       "      <td>2.49303</td>\n",
       "      <td>0.74774</td>\n",
       "      <td>6.01145</td>\n",
       "      <td>9.14703</td>\n",
       "      <td>3.34126</td>\n",
       "      <td>4.10024</td>\n",
       "      <td>0.41432</td>\n",
       "      <td>...</td>\n",
       "      <td>16.21404</td>\n",
       "      <td>0.04572</td>\n",
       "      <td>4.70639</td>\n",
       "      <td>3502.35352</td>\n",
       "      <td>4495</td>\n",
       "      <td>10646</td>\n",
       "      <td>1420</td>\n",
       "      <td>9226</td>\n",
       "      <td>3042845.750</td>\n",
       "      <td>1744.37549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.12647</td>\n",
       "      <td>0.66081</td>\n",
       "      <td>0.88106</td>\n",
       "      <td>2.77796</td>\n",
       "      <td>0.75613</td>\n",
       "      <td>5.16639</td>\n",
       "      <td>10.15986</td>\n",
       "      <td>3.13970</td>\n",
       "      <td>3.91218</td>\n",
       "      <td>0.39423</td>\n",
       "      <td>...</td>\n",
       "      <td>5.78366</td>\n",
       "      <td>0.05878</td>\n",
       "      <td>4.47165</td>\n",
       "      <td>2767.90771</td>\n",
       "      <td>4022</td>\n",
       "      <td>10410</td>\n",
       "      <td>1656</td>\n",
       "      <td>8754</td>\n",
       "      <td>3174905.250</td>\n",
       "      <td>1781.82642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.12322</td>\n",
       "      <td>0.65647</td>\n",
       "      <td>0.87699</td>\n",
       "      <td>2.66837</td>\n",
       "      <td>0.76188</td>\n",
       "      <td>6.34509</td>\n",
       "      <td>9.91083</td>\n",
       "      <td>3.27109</td>\n",
       "      <td>3.97261</td>\n",
       "      <td>0.40030</td>\n",
       "      <td>...</td>\n",
       "      <td>16.15302</td>\n",
       "      <td>0.04413</td>\n",
       "      <td>4.89185</td>\n",
       "      <td>4565.53125</td>\n",
       "      <td>4259</td>\n",
       "      <td>12066</td>\n",
       "      <td>473</td>\n",
       "      <td>11593</td>\n",
       "      <td>5180411.500</td>\n",
       "      <td>2276.05176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8043 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5         6        7   \\\n",
       "0     0.06081  0.75858  0.85508  2.61725  0.71279  9.07447   9.53269  3.54796   \n",
       "1     0.05805  0.80593  0.86047  2.88797  0.70327  8.43171  10.18995  3.56138   \n",
       "2     0.05735  0.80487  0.86085  2.89208  0.69992  8.27271  10.48810  3.61427   \n",
       "3     0.07138  0.60490  0.87878  2.49509  0.74577  7.20000   9.16320  3.48943   \n",
       "4     0.06371  0.61074  0.88761  2.71714  0.74178  8.10054   9.98028  3.60307   \n",
       "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
       "2103  0.06155  0.69752  0.89054  3.18606  0.74120  7.02580  11.77003  3.62602   \n",
       "2104  0.06068  0.75961  0.86736  2.86349  0.71831  7.67092  10.40712  3.60249   \n",
       "2105  0.09644  0.70322  0.85896  2.49303  0.74774  6.01145   9.14703  3.34126   \n",
       "2106  0.12647  0.66081  0.88106  2.77796  0.75613  5.16639  10.15986  3.13970   \n",
       "2107  0.12322  0.65647  0.87699  2.66837  0.76188  6.34509   9.91083  3.27109   \n",
       "\n",
       "           8        9   ...        21       22       23          24    25  \\\n",
       "0     4.38729  0.39242  ...  60.42937  0.03730  4.83596  3644.60889  7689   \n",
       "1     4.49190  0.41046  ...  38.84860  0.03628  4.89183  3413.93018  7340   \n",
       "2     4.52479  0.40255  ...  36.57544  0.03675  4.85308  3305.78662  6990   \n",
       "3     4.20273  0.32976  ...  28.97285  0.03326  5.07144  3614.73560  7340   \n",
       "4     4.32808  0.32754  ...  35.43299  0.02961  5.22304  4149.30322  8214   \n",
       "...       ...      ...  ...       ...      ...      ...         ...   ...   \n",
       "2103  4.42574  0.39767  ...  14.36549  0.03582  4.90722  3821.18237  5915   \n",
       "2104  4.47293  0.40430  ...  27.55488  0.03788  4.86279  4307.60449  5678   \n",
       "2105  4.10024  0.41432  ...  16.21404  0.04572  4.70639  3502.35352  4495   \n",
       "2106  3.91218  0.39423  ...   5.78366  0.05878  4.47165  2767.90771  4022   \n",
       "2107  3.97261  0.40030  ...  16.15302  0.04413  4.89185  4565.53125  4259   \n",
       "\n",
       "         26    27     28           29          30  \n",
       "0     10486  4019   6467  1706812.750  1306.45044  \n",
       "1     10486  4019   6467  1868834.875  1367.05334  \n",
       "2     10311  3845   6466  1798897.125  1341.22974  \n",
       "3     11884  3845   8039  2424746.750  1557.15979  \n",
       "4     12058  3845   8213  2890672.500  1700.19775  \n",
       "...     ...   ...    ...          ...         ...  \n",
       "2103  10883  2129   8754  3848079.250  1961.65222  \n",
       "2104  10646  1656   8990  3530869.500  1879.06079  \n",
       "2105  10646  1420   9226  3042845.750  1744.37549  \n",
       "2106  10410  1656   8754  3174905.250  1781.82642  \n",
       "2107  12066   473  11593  5180411.500  2276.05176  \n",
       "\n",
       "[8043 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9ffd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_32 = df.iloc[:,31]  # вероятности больных по расст от центра\n",
    "feature_33 = df.iloc[:,32]  # вероятности больных по пересеч с маской"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713fdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_33.where(feature_33<0.95, other=1, inplace=True)\n",
    "big_prob_feature_33 = feature_33 > 0.05  # there is no feature less than 0.05\n",
    "feature_33 = feature_33[big_prob_feature_33]\n",
    "Y = feature_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11761114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.658769</td>\n",
       "      <td>-0.388568</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.893271</td>\n",
       "      <td>0.168592</td>\n",
       "      <td>1.007406</td>\n",
       "      <td>0.996314</td>\n",
       "      <td>1.102418</td>\n",
       "      <td>0.480440</td>\n",
       "      <td>-0.489884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333025</td>\n",
       "      <td>-1.016576</td>\n",
       "      <td>0.676326</td>\n",
       "      <td>-1.419898</td>\n",
       "      <td>-1.606353</td>\n",
       "      <td>-1.792862</td>\n",
       "      <td>-0.994495</td>\n",
       "      <td>-1.588028</td>\n",
       "      <td>-1.001290</td>\n",
       "      <td>-1.372388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.768904</td>\n",
       "      <td>-0.176755</td>\n",
       "      <td>1.068378</td>\n",
       "      <td>1.325875</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>1.266773</td>\n",
       "      <td>1.169118</td>\n",
       "      <td>0.840055</td>\n",
       "      <td>-0.277057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.589243</td>\n",
       "      <td>-1.096587</td>\n",
       "      <td>0.822323</td>\n",
       "      <td>-1.452464</td>\n",
       "      <td>-1.638076</td>\n",
       "      <td>-1.792862</td>\n",
       "      <td>-0.994495</td>\n",
       "      <td>-1.588028</td>\n",
       "      <td>-0.995633</td>\n",
       "      <td>-1.349013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.796837</td>\n",
       "      <td>-0.181497</td>\n",
       "      <td>1.073294</td>\n",
       "      <td>1.332442</td>\n",
       "      <td>-0.121230</td>\n",
       "      <td>0.331290</td>\n",
       "      <td>1.389460</td>\n",
       "      <td>1.431993</td>\n",
       "      <td>0.953120</td>\n",
       "      <td>-0.370375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616231</td>\n",
       "      <td>-1.059719</td>\n",
       "      <td>0.721063</td>\n",
       "      <td>-1.467731</td>\n",
       "      <td>-1.669890</td>\n",
       "      <td>-1.803664</td>\n",
       "      <td>-1.017111</td>\n",
       "      <td>-1.588102</td>\n",
       "      <td>-0.998075</td>\n",
       "      <td>-1.358973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.236982</td>\n",
       "      <td>-1.076033</td>\n",
       "      <td>1.305248</td>\n",
       "      <td>0.698062</td>\n",
       "      <td>0.911277</td>\n",
       "      <td>-0.573315</td>\n",
       "      <td>0.844271</td>\n",
       "      <td>0.811511</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>-1.229118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706493</td>\n",
       "      <td>-1.333484</td>\n",
       "      <td>1.291670</td>\n",
       "      <td>-1.424115</td>\n",
       "      <td>-1.638076</td>\n",
       "      <td>-1.706570</td>\n",
       "      <td>-1.017111</td>\n",
       "      <td>-1.471346</td>\n",
       "      <td>-0.976223</td>\n",
       "      <td>-1.275687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.543047</td>\n",
       "      <td>-1.049908</td>\n",
       "      <td>1.419478</td>\n",
       "      <td>1.052893</td>\n",
       "      <td>0.821425</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>1.180495</td>\n",
       "      <td>1.376327</td>\n",
       "      <td>0.276895</td>\n",
       "      <td>-1.255308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629795</td>\n",
       "      <td>-1.619799</td>\n",
       "      <td>1.687822</td>\n",
       "      <td>-1.348647</td>\n",
       "      <td>-1.558632</td>\n",
       "      <td>-1.695829</td>\n",
       "      <td>-1.017111</td>\n",
       "      <td>-1.458430</td>\n",
       "      <td>-0.959956</td>\n",
       "      <td>-1.220516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>-0.629240</td>\n",
       "      <td>-0.661711</td>\n",
       "      <td>1.457382</td>\n",
       "      <td>1.802215</td>\n",
       "      <td>0.808364</td>\n",
       "      <td>-0.720216</td>\n",
       "      <td>1.916966</td>\n",
       "      <td>1.490393</td>\n",
       "      <td>0.612618</td>\n",
       "      <td>-0.427947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.879920</td>\n",
       "      <td>-1.132671</td>\n",
       "      <td>0.862539</td>\n",
       "      <td>-1.394970</td>\n",
       "      <td>-1.767604</td>\n",
       "      <td>-1.768357</td>\n",
       "      <td>-1.240160</td>\n",
       "      <td>-1.418275</td>\n",
       "      <td>-0.926528</td>\n",
       "      <td>-1.119671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>-0.663956</td>\n",
       "      <td>-0.383961</td>\n",
       "      <td>1.157511</td>\n",
       "      <td>1.286756</td>\n",
       "      <td>0.292898</td>\n",
       "      <td>-0.176193</td>\n",
       "      <td>1.356137</td>\n",
       "      <td>1.373444</td>\n",
       "      <td>0.774842</td>\n",
       "      <td>-0.349730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.723328</td>\n",
       "      <td>-0.971079</td>\n",
       "      <td>0.746437</td>\n",
       "      <td>-1.326298</td>\n",
       "      <td>-1.789147</td>\n",
       "      <td>-1.782986</td>\n",
       "      <td>-1.301641</td>\n",
       "      <td>-1.400757</td>\n",
       "      <td>-0.937603</td>\n",
       "      <td>-1.151527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.763015</td>\n",
       "      <td>-0.636213</td>\n",
       "      <td>1.048844</td>\n",
       "      <td>0.694770</td>\n",
       "      <td>0.955640</td>\n",
       "      <td>-1.575607</td>\n",
       "      <td>0.837618</td>\n",
       "      <td>0.075074</td>\n",
       "      <td>-0.506346</td>\n",
       "      <td>-0.231518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.857973</td>\n",
       "      <td>-0.356089</td>\n",
       "      <td>0.337741</td>\n",
       "      <td>-1.439981</td>\n",
       "      <td>-1.896678</td>\n",
       "      <td>-1.782986</td>\n",
       "      <td>-1.332317</td>\n",
       "      <td>-1.383240</td>\n",
       "      <td>-0.954642</td>\n",
       "      <td>-1.203477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>1.961335</td>\n",
       "      <td>-0.825928</td>\n",
       "      <td>1.334743</td>\n",
       "      <td>1.150081</td>\n",
       "      <td>1.144576</td>\n",
       "      <td>-2.288238</td>\n",
       "      <td>1.254391</td>\n",
       "      <td>-0.926722</td>\n",
       "      <td>-1.152835</td>\n",
       "      <td>-0.468531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.981808</td>\n",
       "      <td>0.668371</td>\n",
       "      <td>-0.275668</td>\n",
       "      <td>-1.543667</td>\n",
       "      <td>-1.939672</td>\n",
       "      <td>-1.797553</td>\n",
       "      <td>-1.301641</td>\n",
       "      <td>-1.418275</td>\n",
       "      <td>-0.950032</td>\n",
       "      <td>-1.189031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>1.831647</td>\n",
       "      <td>-0.845342</td>\n",
       "      <td>1.282091</td>\n",
       "      <td>0.974959</td>\n",
       "      <td>1.274062</td>\n",
       "      <td>-1.294252</td>\n",
       "      <td>1.151917</td>\n",
       "      <td>-0.273686</td>\n",
       "      <td>-0.945096</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.858697</td>\n",
       "      <td>-0.480813</td>\n",
       "      <td>0.822375</td>\n",
       "      <td>-1.289885</td>\n",
       "      <td>-1.918129</td>\n",
       "      <td>-1.695335</td>\n",
       "      <td>-1.455409</td>\n",
       "      <td>-1.207549</td>\n",
       "      <td>-0.880009</td>\n",
       "      <td>-0.998404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8043 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.658769 -0.388568  0.998650  0.893271  0.168592  1.007406  0.996314   \n",
       "1    -0.768904 -0.176755  1.068378  1.325875 -0.045791  0.465373  1.266773   \n",
       "2    -0.796837 -0.181497  1.073294  1.332442 -0.121230  0.331290  1.389460   \n",
       "3    -0.236982 -1.076033  1.305248  0.698062  0.911277 -0.573315  0.844271   \n",
       "4    -0.543047 -1.049908  1.419478  1.052893  0.821425  0.186101  1.180495   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2103 -0.629240 -0.661711  1.457382  1.802215  0.808364 -0.720216  1.916966   \n",
       "2104 -0.663956 -0.383961  1.157511  1.286756  0.292898 -0.176193  1.356137   \n",
       "2105  0.763015 -0.636213  1.048844  0.694770  0.955640 -1.575607  0.837618   \n",
       "2106  1.961335 -0.825928  1.334743  1.150081  1.144576 -2.288238  1.254391   \n",
       "2107  1.831647 -0.845342  1.282091  0.974959  1.274062 -1.294252  1.151917   \n",
       "\n",
       "            7         8         9   ...        21        22        23  \\\n",
       "0     1.102418  0.480440 -0.489884  ... -0.333025 -1.016576  0.676326   \n",
       "1     1.169118  0.840055 -0.277057  ... -0.589243 -1.096587  0.822323   \n",
       "2     1.431993  0.953120 -0.370375  ... -0.616231 -1.059719  0.721063   \n",
       "3     0.811511 -0.154018 -1.229118  ... -0.706493 -1.333484  1.291670   \n",
       "4     1.376327  0.276895 -1.255308  ... -0.629795 -1.619799  1.687822   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2103  1.490393  0.612618 -0.427947  ... -0.879920 -1.132671  0.862539   \n",
       "2104  1.373444  0.774842 -0.349730  ... -0.723328 -0.971079  0.746437   \n",
       "2105  0.075074 -0.506346 -0.231518  ... -0.857973 -0.356089  0.337741   \n",
       "2106 -0.926722 -1.152835 -0.468531  ... -0.981808  0.668371 -0.275668   \n",
       "2107 -0.273686 -0.945096 -0.396920  ... -0.858697 -0.480813  0.822375   \n",
       "\n",
       "            24        25        26        27        28        29        30  \n",
       "0    -1.419898 -1.606353 -1.792862 -0.994495 -1.588028 -1.001290 -1.372388  \n",
       "1    -1.452464 -1.638076 -1.792862 -0.994495 -1.588028 -0.995633 -1.349013  \n",
       "2    -1.467731 -1.669890 -1.803664 -1.017111 -1.588102 -0.998075 -1.358973  \n",
       "3    -1.424115 -1.638076 -1.706570 -1.017111 -1.471346 -0.976223 -1.275687  \n",
       "4    -1.348647 -1.558632 -1.695829 -1.017111 -1.458430 -0.959956 -1.220516  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2103 -1.394970 -1.767604 -1.768357 -1.240160 -1.418275 -0.926528 -1.119671  \n",
       "2104 -1.326298 -1.789147 -1.782986 -1.301641 -1.400757 -0.937603 -1.151527  \n",
       "2105 -1.439981 -1.896678 -1.782986 -1.332317 -1.383240 -0.954642 -1.203477  \n",
       "2106 -1.543667 -1.939672 -1.797553 -1.301641 -1.418275 -0.950032 -1.189031  \n",
       "2107 -1.289885 -1.918129 -1.695335 -1.455409 -1.207549 -0.880009 -0.998404  \n",
       "\n",
       "[8043 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = X0.mean()\n",
    "sig = X0.std()\n",
    "X = (X0 - mu)/sig\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8f4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ca64834",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[df['files_indices']<32]\n",
    "X_test = X[df['files_indices']>=32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee492960",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[df['files_indices']<32]\n",
    "y_test = Y[df['files_indices']>=32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab709b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216    0.65111\n",
       "4217    0.58444\n",
       "4218    0.50778\n",
       "4219    0.48444\n",
       "4220    0.67333\n",
       "4221    0.80778\n",
       "4222    0.76111\n",
       "4223    0.67667\n",
       "4224    0.58444\n",
       "4225    0.33444\n",
       "4226    0.46889\n",
       "4227    0.57444\n",
       "4228    0.52778\n",
       "1399    1.00000\n",
       "1400    1.00000\n",
       "1401    1.00000\n",
       "1402    1.00000\n",
       "1403    1.00000\n",
       "1404    1.00000\n",
       "1405    1.00000\n",
       "1406    1.00000\n",
       "1407    1.00000\n",
       "1408    1.00000\n",
       "1409    1.00000\n",
       "1410    1.00000\n",
       "1411    1.00000\n",
       "1412    1.00000\n",
       "1413    1.00000\n",
       "1414    1.00000\n",
       "1415    1.00000\n",
       "1416    1.00000\n",
       "1417    1.00000\n",
       "1418    1.00000\n",
       "1419    1.00000\n",
       "1420    1.00000\n",
       "1421    1.00000\n",
       "1422    1.00000\n",
       "1423    1.00000\n",
       "1424    1.00000\n",
       "1425    1.00000\n",
       "1426    1.00000\n",
       "1427    1.00000\n",
       "1428    1.00000\n",
       "1429    1.00000\n",
       "1430    1.00000\n",
       "1431    1.00000\n",
       "1432    1.00000\n",
       "1433    1.00000\n",
       "1434    1.00000\n",
       "1435    1.00000\n",
       "1436    1.00000\n",
       "1437    1.00000\n",
       "1438    1.00000\n",
       "1439    1.00000\n",
       "1440    1.00000\n",
       "1441    1.00000\n",
       "1442    1.00000\n",
       "1443    1.00000\n",
       "1444    1.00000\n",
       "1445    1.00000\n",
       "Name: 32, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31a1d7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4229    0.49778\n",
       "4230    1.00000\n",
       "4231    1.00000\n",
       "4232    0.85111\n",
       "4233    0.69333\n",
       "4234    0.46889\n",
       "4235    1.00000\n",
       "4236    1.00000\n",
       "4237    1.00000\n",
       "4238    1.00000\n",
       "4239    0.84667\n",
       "4240    0.66444\n",
       "4241    1.00000\n",
       "4242    1.00000\n",
       "4243    1.00000\n",
       "4244    1.00000\n",
       "4245    1.00000\n",
       "4246    1.00000\n",
       "4247    0.94778\n",
       "4248    0.82000\n",
       "4249    0.62889\n",
       "4250    0.94556\n",
       "4251    1.00000\n",
       "4252    1.00000\n",
       "4253    1.00000\n",
       "4254    1.00000\n",
       "4255    1.00000\n",
       "4256    1.00000\n",
       "4257    1.00000\n",
       "4258    0.92111\n",
       "4259    0.76556\n",
       "4260    0.53222\n",
       "4261    0.68556\n",
       "4262    0.89333\n",
       "4263    1.00000\n",
       "4264    1.00000\n",
       "4265    1.00000\n",
       "4266    1.00000\n",
       "4267    1.00000\n",
       "4268    1.00000\n",
       "Name: 32, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afa3ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(class_1, class_2, disp_data=1):  # negative, positive\n",
    "#     rng(1337,'twister')\n",
    "#     s = rng\n",
    "#     class_1 = rand(1,3);\n",
    "#     rng(s)\n",
    "#     class_2 = 0.5*rand(1,5);\n",
    "#     sispt = 1;\n",
    "#     dispp = 1;\n",
    "\n",
    "#     np.random.seed(1337)\n",
    "#     class_1 = np.random.rand(1,3)\n",
    "#     np.random.seed(1337)\n",
    "#     class_2 = 0.5*np.random.rand(1,3)\n",
    "\n",
    "    # Calculating the threshold values between the data points\n",
    "    s_data = np.sort(np.unique(np.concatenate([class_1, class_2], axis=0)))\n",
    "    s_data = s_data[s_data!=np.array(None)]\n",
    "    d_data = np.diff(s_data)\n",
    "    if np.all(d_data==0):\n",
    "        print('Both class are the same!')\n",
    "    d_data = np.append(d_data, d_data[-1])\n",
    "    thres = np.empty(len(s_data)+1)\n",
    "    thres[0] = s_data[0] - d_data[0]\n",
    "    thres[1:len(thres)] = s_data + d_data/2\n",
    "\n",
    "    # Calculating the sensibility and specificity of each threshold\n",
    "    curve = np.zeros((len(thres),2))\n",
    "    distance = np.zeros((len(thres),1))\n",
    "    for id_t in range(len(thres)):\n",
    "        TP = np.sum(class_2 >= thres[id_t])\n",
    "        FP = np.sum(class_1 >= thres[id_t])\n",
    "        FN = np.sum(class_2 < thres[id_t])\n",
    "        TN = np.sum(class_1 < thres[id_t])\n",
    "\n",
    "        curve[id_t, 0] = TP/(TP+FN)  # sensitivity - TPR\n",
    "        curve[id_t, 1] = TN/(TN+FP)  # specificity - FPR\n",
    "\n",
    "        distance[id_t] = np.sqrt((1-curve[id_t, 0])**2 + (curve[id_t,1]-1)**2)\n",
    "\n",
    "    # Optimum threshold and parameters\n",
    "    #opt = np.min(distance)  # 1\n",
    "    opt = np.argmin(distance)\n",
    "    TP = np.sum(class_2 >= thres[opt])\n",
    "    FP = np.sum(class_1 >= thres[opt])\n",
    "    FN = np.sum(class_2 < thres[opt])\n",
    "    TN = np.sum(class_1 < thres[opt])\n",
    "\n",
    "    if disp_data==1:\n",
    "        print('\\n ROC CURVE PARAMETERS:\\n')\n",
    "        print('Threshold:', thres[opt])\n",
    "        print('Distance:', distance[opt])\n",
    "        print('Sensitivity:', curve[opt,0])\n",
    "        print('Specificity:', curve[opt,1])\n",
    "        print('Accuracy:', (TP+TN)/(TP+TN+FP+FN))\n",
    "        print('PPV:', TP/(TP+FP))\n",
    "        print('NPV:', TN/(TN+FN))\n",
    "        print('FNR:', FN/(FN+TP))\n",
    "        print('FPR:', FP/(FP+TN))\n",
    "        print('FDR:', FP/(FP+TP))\n",
    "        print('FOR:', FN/(FN+TN))\n",
    "        print('F1 score:', 2*TP/(2*TP+FP+FN))\n",
    "        print('TP:', TP)\n",
    "        print('FP:', FP)\n",
    "        print('FN:', FN)\n",
    "        print('TN:', TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0702b",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8dc92ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def clus_en_matrix(X, L):  # 10, 100\n",
    "    n = len(X)\n",
    "    c_mem = np.zeros((n,L), dtype=int)\n",
    "    A_m = [None]*L\n",
    "    print(len(A_m))\n",
    "    K_l = np.zeros(L, dtype=int)\n",
    "    D = csr_matrix((n,n), dtype='int')\n",
    "#     opts = ...\n",
    "    for l in range(L):\n",
    "        C = DBSCAN(eps=l, min_samples=3).fit(X)\n",
    "        c_mem[:,l] = C.labels_\n",
    "        print(len(c_mem[:,l]))\n",
    "        \n",
    "    A_m[l] = csr_matrix((np.ones(n, dtype='int'),\n",
    "                (np.arange(n),c_mem[:,l])), shape=(n,L))\n",
    "        \n",
    "    A = A_m[1]\n",
    "    for l in range(1,L):\n",
    "        A = hstack([A, A_m[l]])\n",
    "    \n",
    "    A = np.sqrt(1/L)*A\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1c04729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "8043\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "column index exceeds matrix dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_9596/4147919002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclus_en_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_9596/113111077.py\u001b[0m in \u001b[0;36mclus_en_matrix\u001b[1;34m(X, L, K)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         A_m[l] = csr_matrix((np.ones(n, dtype='int'),\n\u001b[0m\u001b[0;32m     22\u001b[0m                     (np.arange(n),c_mem[:,l])), shape=(n,K+l))\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[1;31m# (data, ij) format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                     other = self.__class__(coo_matrix(arg1, shape=shape,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                                       dtype=dtype))\n\u001b[0;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'row index exceeds matrix dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'column index exceeds matrix dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative row index found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: column index exceeds matrix dimensions"
     ]
    }
   ],
   "source": [
    "clus_en_matrix(X, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79ffc3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_m = [1]*1\n",
    "A_m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "682c2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "dsbcan_clf = DBSCAN()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(eps=list(range(1, 5)), min_samples=list(range(1, 5)))\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(dsbcan_clf, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X)\n",
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\n",
    "#DBSCAN(eps=3, min_samples=3).fit(X).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202dd0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd89837",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a267b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# knn.fit(X_train, y_train_encoded)\n",
    "# y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def clus_en_matrix(X, K):  # X, K - number of kneighbors\n",
    "    n = len(X)\n",
    "    c_mem = np.zeros((n,L), dtype=int)\n",
    "    A_m = [None]*L\n",
    "    K_l = np.zeros(L, dtype=int)\n",
    "    D = csr_matrix((n,n), dtype='int')\n",
    "#     opts = ...\n",
    "    for l in range(L):\n",
    "        C = KNeighborsClassifier(n_neighbors=K).fit(X)\n",
    "        c_mem[:,l] = C.labels_\n",
    "        \n",
    "    for l in range(L):\n",
    "        A_m[l] = csr_matrix((np.ones(n, dtype='int'),\n",
    "                    (np.arange(n),c_mem[:,l])), shape=(n,K+l))\n",
    "        \n",
    "    A = A_m[1]\n",
    "    for l in range(1,L):\n",
    "        A = hstack([A, A_m[l]])\n",
    "    \n",
    "    A = np.sqrt(1/L)*A\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03a96876",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_8248/1287014428.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mind_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0minp_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# all indexes with number 1,2,3,...,46,1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind_files\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# concatenate indexes in loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnew_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# новый порядок объектов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indexes' is not defined"
     ]
    }
   ],
   "source": [
    "for n_file in range(n_files):\n",
    "    inp_files = [i for i in range(n_files) if i!=n_file] + [n_file]\n",
    "    inp = []\n",
    "    for j in range(n_files):\n",
    "        ind_files = [i for i, x in enumerate(indexes) if x==inp_files[j]]  # all indexes with number 1,2,3,...,46,1\n",
    "        inp.extend(ind_files)  # concatenate indexes in loop\n",
    "    new_indexes = indexes[inp]  # новый порядок объектов\n",
    "    \n",
    "    # какие объекы в последних контрольных снимках\n",
    "    tes_test = np.isin(indexes, inp_files[len(inp_files)-n_test_files:len(inp_files)])  # inp_files[46:46]\n",
    "    n_test_0 = sum(tes_test)  # количество объектов в контрольной выборке = 277\n",
    "        \n",
    "    # какие объекы в неточных снимках\n",
    "    tes_uncertain = np.isin(indexes, inp_files[n_certain_files:n_certain_files+n_uncertain_files])  # 1,2,...,45\n",
    "    n_uncertain = sum(tes_uncertain)  # количество объектов в неточной выборке = 7766\n",
    "        \n",
    "    # какие объекы в точных снимках\n",
    "    tes_certain = np.isin(indexes, inp_files[:n_certain_files])  # empty\n",
    "    n_certain = sum(tes_certain)  # количество объектов в точной выборке = 0\n",
    "        \n",
    "    X = X0.iloc[inp]\n",
    "    Y_pos = Y_pos_0.iloc[inp]\n",
    "    Y1M = Y1M0.iloc[inp]\n",
    "    \n",
    "    ind_insult = Y1M==1  # уверенно классиф как больные\n",
    "    ind_healthy = Y1M==0  # уверенно классиф как здоровые\n",
    "    ind_certain = np.logical_or(ind_insult,ind_healthy)  # 4958 уверенно классифицированных данных\n",
    "    \n",
    "    Y10Tr = np.array([[*ind_insult[:n_certain], *Y_pos[n_certain:n_certain+n_uncertain], *pd.Series(np.zeros((n_test_0,), dtype=int))],\n",
    "                      [*ind_healthy[:n_certain], *(1-Y_pos[n_certain:n_certain+n_uncertain]), *pd.Series(np.zeros((n_test_0,), dtype=int))]]).T\n",
    "    \n",
    "    Y1MC = Y1M[n-n_test_0:len(Y1M)]  # 8043-277 : 8043 (last)\n",
    "    Y_true_test = 1+(Y1MC[ind_certain[n-n_test_0:len(ind_certain)]]==0)\n",
    "    \n",
    "#     Y10Tr2 = Y10Tr\n",
    "#     ind_uncertain = np.logical_not(ind_certain)\n",
    "#     Y10Tr2[ind_uncertain][n_certain:n-n_test_0, :] = 0\n",
    "    \n",
    "    #print(Y10Tr2)\n",
    "    \n",
    "    sigma = 1.25\n",
    "    bet = 0.001\n",
    "    mmax = 1000\n",
    "    G = bet * eye(n, dtype='int') + csr_matrix(([*pd.to_numeric(ind_certain[:n_certain], errors='coerce'),\n",
    "                 *np.ones(n_uncertain, dtype='int'),\n",
    "                 *np.zeros(n_test_0, dtype='int')],\n",
    "                (np.arange(n),np.arange(n))), shape=(n,n))\n",
    "    G2 = bet * eye(n, dtype='int') + csr_matrix(([*pd.to_numeric(ind_certain[:n-n_test_0], errors='coerce'),\n",
    "                  *np.zeros(n_test_0, dtype='int')],\n",
    "                (np.arange(n),np.arange(n))), shape=(n,n))\n",
    "    \n",
    "    A = clus_en_matrix(X,10,100)\n",
    "    m = A.shape[1]  # 1046 in order of 1055\n",
    "    u = A.sum(axis = 0)  # by columns\n",
    "    dd = A * u.conj().transpose()  # 8043x1 array\n",
    "    dd[dd<0] = 0\n",
    "    D = csr_matrix(([item for sublist in dd.tolist() for item in sublist], \n",
    "                    (np.arange(n), np.arange(n))), shape=(n,n), dtype='int')\n",
    "    D = csr_matrix((1/np.sqrt(D.diagonal()),\n",
    "                    (np.arange(n), np.arange(n))), shape=(n,n))\n",
    "    U = D*A\n",
    "    Gm = csr_matrix((1/G.diagonal(),\n",
    "                    (np.arange(n), np.arange(n))), shape=(n,n))\n",
    "    A1 = bet * Gm * U\n",
    "    A2 = eye(m, dtype='int') - bet*(U.conj().transpose() * Gm)*U\n",
    "\n",
    "    F = np.empty(shape=[n,K]) \n",
    "    for k in range(K):\n",
    "        A3 = inv(A2) * (U.conj().transpose() * Gm * Y10Tr[:,k])\n",
    "        F[:,k] = Gm * Y10Tr[:,k] + A1 * A3\n",
    "        \n",
    "    F = F/F.sum(axis = 1).reshape((n,1))  # нормировка\n",
    "    Ff = F[n-n_test_0:,]\n",
    "    Ft = Ff[ind_certain[n-n_test_0:],]\n",
    "\n",
    "    class11 = Ft[Y_true_test==2, 0]  # negative\n",
    "    class21 = Ft[Y_true_test==1, 0]  # positive\n",
    "    roc_curve(class11, class21, 1)\n",
    "    print(n_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3995d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 204, 234, ..., 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ValueError: Unknown label type: 'continuous'\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ddfef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([272, 213, 146, 126, 292, 409, 370, 295, 213,  28, 112, 204, 164,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a8c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 29 candidates, totalling 290 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 30))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e6720e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 29}\n",
      "Accuracy for our training dataset with tuning is : 61.78%\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea49227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50eda58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([536, 536, 536, ..., 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=29)\n",
    "knn.fit(X_train, y_train_encoded)\n",
    "y_pred=knn.predict(X_test) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fb31ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79, 433, 433, ..., 433, 433, 433], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_enc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "754f15f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for our testing dataset with tuning is : 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "test_accuracy=accuracy_score(lab_enc.fit_transform(y_test),y_pred)*100\n",
    "print(\"Accuracy for our testing dataset with tuning is : {:.2f}%\".format(test_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14aafc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "           2       0.00      0.00      0.00       1.0\n",
      "           3       0.00      0.00      0.00       1.0\n",
      "           4       0.00      0.00      0.00       1.0\n",
      "           5       0.00      0.00      0.00       2.0\n",
      "           6       0.00      0.00      0.00       2.0\n",
      "           7       0.00      0.00      0.00       2.0\n",
      "           8       0.00      0.00      0.00       1.0\n",
      "           9       0.00      0.00      0.00       2.0\n",
      "          10       0.00      0.00      0.00       1.0\n",
      "          11       0.00      0.00      0.00       1.0\n",
      "          12       0.00      0.00      0.00       1.0\n",
      "          13       0.00      0.00      0.00       1.0\n",
      "          14       0.00      0.00      0.00       1.0\n",
      "          15       0.00      0.00      0.00       1.0\n",
      "          16       0.00      0.00      0.00       1.0\n",
      "          17       0.00      0.00      0.00       2.0\n",
      "          18       0.00      0.00      0.00       1.0\n",
      "          19       0.00      0.00      0.00       1.0\n",
      "          20       0.00      0.00      0.00       1.0\n",
      "          21       0.00      0.00      0.00       1.0\n",
      "          22       0.00      0.00      0.00       1.0\n",
      "          23       0.00      0.00      0.00       1.0\n",
      "          24       0.00      0.00      0.00       1.0\n",
      "          25       0.00      0.00      0.00       1.0\n",
      "          26       0.00      0.00      0.00       1.0\n",
      "          27       0.00      0.00      0.00       1.0\n",
      "          28       0.00      0.00      0.00       2.0\n",
      "          29       0.00      0.00      0.00       1.0\n",
      "          30       0.00      0.00      0.00       1.0\n",
      "          31       0.00      0.00      0.00       1.0\n",
      "          32       0.00      0.00      0.00       1.0\n",
      "          33       0.00      0.00      0.00       1.0\n",
      "          34       0.00      0.00      0.00       1.0\n",
      "          35       0.00      0.00      0.00       1.0\n",
      "          36       0.00      0.00      0.00       1.0\n",
      "          37       0.00      0.00      0.00       2.0\n",
      "          38       0.00      0.00      0.00       1.0\n",
      "          39       0.00      0.00      0.00       1.0\n",
      "          40       0.00      0.00      0.00       1.0\n",
      "          41       0.00      0.00      0.00       1.0\n",
      "          42       0.00      0.00      0.00       1.0\n",
      "          43       0.00      0.00      0.00       2.0\n",
      "          44       0.00      0.00      0.00       2.0\n",
      "          45       0.00      0.00      0.00       1.0\n",
      "          46       0.00      0.00      0.00       1.0\n",
      "          47       0.00      0.00      0.00       1.0\n",
      "          48       0.00      0.00      0.00       2.0\n",
      "          49       0.00      0.00      0.00       1.0\n",
      "          50       0.00      0.00      0.00       1.0\n",
      "          51       0.00      0.00      0.00       2.0\n",
      "          52       0.00      0.00      0.00       2.0\n",
      "          53       0.00      0.00      0.00       1.0\n",
      "          54       0.00      0.00      0.00       2.0\n",
      "          55       0.00      0.00      0.00       1.0\n",
      "          56       0.00      0.00      0.00       1.0\n",
      "          57       0.00      0.00      0.00       1.0\n",
      "          58       0.00      0.00      0.00       1.0\n",
      "          59       0.00      0.00      0.00       2.0\n",
      "          60       0.00      0.00      0.00       1.0\n",
      "          61       0.00      0.00      0.00       1.0\n",
      "          62       0.00      0.00      0.00       5.0\n",
      "          63       0.00      0.00      0.00       1.0\n",
      "          64       0.00      0.00      0.00       2.0\n",
      "          65       0.00      0.00      0.00       3.0\n",
      "          66       0.00      0.00      0.00       1.0\n",
      "          67       0.00      0.00      0.00       1.0\n",
      "          68       0.00      0.00      0.00       3.0\n",
      "          69       0.00      0.00      0.00       1.0\n",
      "          70       0.00      0.00      0.00       1.0\n",
      "          71       0.00      0.00      0.00       1.0\n",
      "          72       0.00      0.00      0.00       2.0\n",
      "          73       0.00      0.00      0.00       1.0\n",
      "          74       0.00      0.00      0.00       1.0\n",
      "          75       0.00      0.00      0.00       4.0\n",
      "          76       0.00      0.00      0.00       4.0\n",
      "          77       0.00      0.00      0.00       1.0\n",
      "          78       0.00      0.00      0.00       1.0\n",
      "          79       0.00      0.00      0.00       3.0\n",
      "          80       0.00      0.00      0.00       1.0\n",
      "          81       0.00      0.00      0.00       1.0\n",
      "          82       0.00      0.00      0.00       3.0\n",
      "          83       0.00      0.00      0.00       2.0\n",
      "          84       0.00      0.00      0.00       3.0\n",
      "          85       0.00      0.00      0.00       2.0\n",
      "          86       0.00      0.00      0.00       2.0\n",
      "          87       0.00      0.00      0.00       1.0\n",
      "          88       0.00      0.00      0.00       3.0\n",
      "          89       0.00      0.00      0.00       2.0\n",
      "          90       0.00      0.00      0.00       3.0\n",
      "          91       0.00      0.00      0.00       2.0\n",
      "          92       0.00      0.00      0.00       3.0\n",
      "          93       0.00      0.00      0.00       2.0\n",
      "          94       0.00      0.00      0.00       3.0\n",
      "          95       0.00      0.00      0.00       1.0\n",
      "          96       0.00      0.00      0.00       2.0\n",
      "          97       0.00      0.00      0.00       2.0\n",
      "          98       0.00      0.00      0.00       1.0\n",
      "          99       0.00      0.00      0.00       1.0\n",
      "         100       0.00      0.00      0.00       2.0\n",
      "         101       0.00      0.00      0.00       4.0\n",
      "         102       0.00      0.00      0.00       2.0\n",
      "         103       0.00      0.00      0.00       1.0\n",
      "         104       0.00      0.00      0.00       4.0\n",
      "         105       0.00      0.00      0.00       2.0\n",
      "         106       0.00      0.00      0.00       1.0\n",
      "         107       0.00      0.00      0.00       2.0\n",
      "         108       0.00      0.00      0.00       3.0\n",
      "         109       0.00      0.00      0.00       2.0\n",
      "         110       0.00      0.00      0.00       1.0\n",
      "         111       0.00      0.00      0.00       1.0\n",
      "         112       0.00      0.00      0.00       1.0\n",
      "         113       0.00      0.00      0.00       2.0\n",
      "         114       0.00      0.00      0.00       3.0\n",
      "         115       0.00      0.00      0.00       4.0\n",
      "         116       0.00      0.00      0.00       1.0\n",
      "         117       0.00      0.00      0.00       3.0\n",
      "         118       0.00      0.00      0.00       1.0\n",
      "         119       0.00      0.00      0.00       1.0\n",
      "         120       0.00      0.00      0.00       4.0\n",
      "         121       0.00      0.00      0.00       1.0\n",
      "         122       0.00      0.00      0.00       3.0\n",
      "         123       0.00      0.00      0.00       3.0\n",
      "         124       0.00      0.00      0.00       3.0\n",
      "         125       0.00      0.00      0.00       1.0\n",
      "         126       0.00      0.00      0.00       2.0\n",
      "         127       0.00      0.00      0.00       1.0\n",
      "         128       0.00      0.00      0.00       2.0\n",
      "         129       0.00      0.00      0.00       3.0\n",
      "         130       0.00      0.00      0.00       2.0\n",
      "         131       0.00      0.00      0.00       5.0\n",
      "         132       0.00      0.00      0.00       5.0\n",
      "         133       0.00      0.00      0.00       4.0\n",
      "         134       0.00      0.00      0.00       2.0\n",
      "         135       0.00      0.00      0.00       2.0\n",
      "         136       0.00      0.00      0.00       1.0\n",
      "         137       0.00      0.00      0.00       2.0\n",
      "         138       0.00      0.00      0.00       1.0\n",
      "         139       0.00      0.00      0.00       4.0\n",
      "         140       0.00      0.00      0.00       3.0\n",
      "         141       0.00      0.00      0.00       1.0\n",
      "         142       0.00      0.00      0.00       3.0\n",
      "         143       0.00      0.00      0.00       2.0\n",
      "         144       0.00      0.00      0.00       2.0\n",
      "         145       0.00      0.00      0.00       4.0\n",
      "         146       0.00      0.00      0.00       1.0\n",
      "         147       0.00      0.00      0.00       3.0\n",
      "         148       0.00      0.00      0.00       1.0\n",
      "         149       0.00      0.00      0.00       1.0\n",
      "         150       0.00      0.00      0.00       2.0\n",
      "         151       0.00      0.00      0.00       3.0\n",
      "         152       0.00      0.00      0.00       3.0\n",
      "         153       0.00      0.00      0.00       1.0\n",
      "         154       0.00      0.00      0.00       1.0\n",
      "         155       0.00      0.00      0.00       1.0\n",
      "         156       0.00      0.00      0.00       4.0\n",
      "         157       0.00      0.00      0.00       1.0\n",
      "         158       0.00      0.00      0.00       3.0\n",
      "         159       0.00      0.00      0.00       2.0\n",
      "         160       0.00      0.00      0.00       2.0\n",
      "         161       0.00      0.00      0.00       3.0\n",
      "         162       0.00      0.00      0.00       2.0\n",
      "         163       0.00      0.00      0.00       2.0\n",
      "         164       0.00      0.00      0.00       2.0\n",
      "         165       0.00      0.00      0.00       4.0\n",
      "         166       0.00      0.00      0.00       2.0\n",
      "         167       0.00      0.00      0.00       1.0\n",
      "         168       0.00      0.00      0.00       2.0\n",
      "         169       0.00      0.00      0.00       1.0\n",
      "         170       0.00      0.00      0.00       1.0\n",
      "         171       0.00      0.00      0.00       2.0\n",
      "         172       0.00      0.00      0.00       4.0\n",
      "         173       0.00      0.00      0.00       3.0\n",
      "         174       0.00      0.00      0.00       2.0\n",
      "         175       0.00      0.00      0.00       4.0\n",
      "         176       0.00      0.00      0.00       4.0\n",
      "         177       0.00      0.00      0.00       3.0\n",
      "         178       0.00      0.00      0.00       2.0\n",
      "         179       0.00      0.00      0.00       3.0\n",
      "         180       0.00      0.00      0.00       2.0\n",
      "         181       0.00      0.00      0.00       1.0\n",
      "         182       0.00      0.00      0.00       1.0\n",
      "         183       0.00      0.00      0.00       3.0\n",
      "         184       0.00      0.00      0.00       3.0\n",
      "         185       0.00      0.00      0.00       3.0\n",
      "         186       0.00      0.00      0.00       3.0\n",
      "         187       0.00      0.00      0.00       3.0\n",
      "         188       0.00      0.00      0.00       4.0\n",
      "         189       0.00      0.00      0.00       2.0\n",
      "         190       0.00      0.00      0.00       2.0\n",
      "         191       0.00      0.00      0.00       4.0\n",
      "         192       0.00      0.00      0.00       3.0\n",
      "         193       0.00      0.00      0.00       2.0\n",
      "         194       0.00      0.00      0.00       3.0\n",
      "         195       0.00      0.00      0.00       3.0\n",
      "         196       0.00      0.00      0.00       2.0\n",
      "         197       0.00      0.00      0.00       1.0\n",
      "         198       0.00      0.00      0.00       2.0\n",
      "         199       0.00      0.00      0.00       1.0\n",
      "         200       0.00      0.00      0.00       4.0\n",
      "         201       0.00      0.00      0.00       1.0\n",
      "         202       0.00      0.00      0.00       1.0\n",
      "         203       0.00      0.00      0.00       4.0\n",
      "         204       0.00      0.00      0.00       2.0\n",
      "         205       0.00      0.00      0.00       2.0\n",
      "         206       0.00      0.00      0.00       2.0\n",
      "         207       0.00      0.00      0.00       2.0\n",
      "         208       0.00      0.00      0.00       3.0\n",
      "         209       0.00      0.00      0.00       4.0\n",
      "         210       0.00      0.00      0.00       2.0\n",
      "         211       0.00      0.00      0.00       3.0\n",
      "         212       0.00      0.00      0.00       3.0\n",
      "         213       0.00      0.00      0.00       1.0\n",
      "         214       0.00      0.00      0.00       6.0\n",
      "         215       0.00      0.00      0.00       2.0\n",
      "         216       0.00      0.00      0.00       1.0\n",
      "         217       0.00      0.00      0.00       2.0\n",
      "         218       0.00      0.00      0.00       1.0\n",
      "         219       0.00      0.00      0.00       5.0\n",
      "         220       0.00      0.00      0.00       2.0\n",
      "         221       0.00      0.00      0.00       2.0\n",
      "         222       0.00      0.00      0.00       1.0\n",
      "         223       0.00      0.00      0.00       4.0\n",
      "         224       0.00      0.00      0.00       2.0\n",
      "         225       0.00      0.00      0.00       2.0\n",
      "         226       0.00      0.00      0.00       1.0\n",
      "         227       0.00      0.00      0.00       1.0\n",
      "         228       0.00      0.00      0.00       3.0\n",
      "         229       0.00      0.00      0.00       5.0\n",
      "         230       0.00      0.00      0.00       1.0\n",
      "         231       0.00      0.00      0.00       3.0\n",
      "         232       0.00      0.00      0.00       2.0\n",
      "         233       0.00      0.00      0.00       2.0\n",
      "         234       0.00      0.00      0.00       1.0\n",
      "         235       0.00      0.00      0.00       2.0\n",
      "         236       0.00      0.00      0.00       1.0\n",
      "         237       0.00      0.00      0.00       2.0\n",
      "         238       0.00      0.00      0.00       5.0\n",
      "         239       0.00      0.00      0.00       1.0\n",
      "         240       0.00      0.00      0.00       2.0\n",
      "         241       0.00      0.00      0.00       2.0\n",
      "         242       0.00      0.00      0.00       2.0\n",
      "         243       0.00      0.00      0.00       2.0\n",
      "         244       0.00      0.00      0.00       1.0\n",
      "         245       0.00      0.00      0.00       1.0\n",
      "         246       0.00      0.00      0.00       1.0\n",
      "         247       0.00      0.00      0.00       2.0\n",
      "         248       0.00      0.00      0.00       2.0\n",
      "         249       0.00      0.00      0.00       4.0\n",
      "         250       0.00      0.00      0.00       3.0\n",
      "         251       0.00      0.00      0.00       2.0\n",
      "         252       0.00      0.00      0.00       4.0\n",
      "         253       0.00      0.00      0.00       3.0\n",
      "         254       0.00      0.00      0.00       3.0\n",
      "         255       0.00      0.00      0.00       1.0\n",
      "         256       0.00      0.00      0.00       2.0\n",
      "         257       0.00      0.00      0.00       5.0\n",
      "         258       0.00      0.00      0.00       2.0\n",
      "         259       0.00      0.00      0.00       2.0\n",
      "         260       0.00      0.00      0.00       2.0\n",
      "         261       0.00      0.00      0.00       2.0\n",
      "         262       0.00      0.00      0.00       3.0\n",
      "         263       0.00      0.00      0.00       2.0\n",
      "         264       0.00      0.00      0.00       2.0\n",
      "         265       0.00      0.00      0.00       4.0\n",
      "         266       0.00      0.00      0.00       2.0\n",
      "         267       0.00      0.00      0.00       2.0\n",
      "         268       0.00      0.00      0.00       2.0\n",
      "         269       0.00      0.00      0.00       3.0\n",
      "         270       0.00      0.00      0.00       2.0\n",
      "         271       0.00      0.00      0.00       2.0\n",
      "         272       0.00      0.00      0.00       2.0\n",
      "         273       0.00      0.00      0.00       2.0\n",
      "         274       0.00      0.00      0.00       3.0\n",
      "         275       0.00      0.00      0.00       4.0\n",
      "         276       0.00      0.00      0.00       3.0\n",
      "         277       0.00      0.00      0.00       1.0\n",
      "         278       0.00      0.00      0.00       1.0\n",
      "         279       0.00      0.00      0.00       3.0\n",
      "         280       0.00      0.00      0.00       5.0\n",
      "         281       0.00      0.00      0.00       3.0\n",
      "         282       0.00      0.00      0.00       1.0\n",
      "         283       0.00      0.00      0.00       2.0\n",
      "         284       0.00      0.00      0.00       1.0\n",
      "         285       0.00      0.00      0.00       4.0\n",
      "         286       0.00      0.00      0.00       3.0\n",
      "         287       0.00      0.00      0.00       4.0\n",
      "         288       0.00      0.00      0.00       1.0\n",
      "         289       0.00      0.00      0.00       1.0\n",
      "         290       0.00      0.00      0.00       4.0\n",
      "         291       0.00      0.00      0.00       1.0\n",
      "         292       0.00      0.00      0.00       4.0\n",
      "         293       0.00      0.00      0.00       4.0\n",
      "         294       0.00      0.00      0.00       2.0\n",
      "         295       0.00      0.00      0.00       4.0\n",
      "         296       0.00      0.00      0.00       3.0\n",
      "         297       0.00      0.00      0.00       1.0\n",
      "         298       0.00      0.00      0.00       1.0\n",
      "         299       0.00      0.00      0.00       1.0\n",
      "         300       0.00      0.00      0.00       2.0\n",
      "         301       0.00      0.00      0.00       5.0\n",
      "         302       0.00      0.00      0.00       3.0\n",
      "         303       0.00      0.00      0.00       3.0\n",
      "         304       0.00      0.00      0.00       2.0\n",
      "         305       0.00      0.00      0.00       4.0\n",
      "         306       0.00      0.00      0.00       3.0\n",
      "         307       0.00      0.00      0.00       1.0\n",
      "         308       0.00      0.00      0.00       2.0\n",
      "         309       0.00      0.00      0.00       3.0\n",
      "         310       0.00      0.00      0.00       1.0\n",
      "         311       0.00      0.00      0.00       4.0\n",
      "         312       0.00      0.00      0.00       1.0\n",
      "         313       0.00      0.00      0.00       4.0\n",
      "         314       0.00      0.00      0.00       3.0\n",
      "         315       0.00      0.00      0.00       2.0\n",
      "         316       0.00      0.00      0.00       3.0\n",
      "         317       0.00      0.00      0.00       1.0\n",
      "         318       0.00      0.00      0.00       2.0\n",
      "         319       0.00      0.00      0.00       2.0\n",
      "         320       0.00      0.00      0.00       1.0\n",
      "         321       0.00      0.00      0.00       2.0\n",
      "         322       0.00      0.00      0.00       1.0\n",
      "         323       0.00      0.00      0.00       1.0\n",
      "         324       0.00      0.00      0.00       5.0\n",
      "         325       0.00      0.00      0.00       2.0\n",
      "         326       0.00      0.00      0.00       3.0\n",
      "         327       0.00      0.00      0.00       2.0\n",
      "         328       0.00      0.00      0.00       2.0\n",
      "         329       0.00      0.00      0.00       2.0\n",
      "         330       0.00      0.00      0.00       5.0\n",
      "         331       0.00      0.00      0.00       1.0\n",
      "         332       0.00      0.00      0.00       5.0\n",
      "         333       0.00      0.00      0.00       3.0\n",
      "         334       0.00      0.00      0.00       5.0\n",
      "         335       0.00      0.00      0.00       4.0\n",
      "         336       0.00      0.00      0.00       3.0\n",
      "         337       0.00      0.00      0.00       4.0\n",
      "         338       0.00      0.00      0.00       6.0\n",
      "         339       0.00      0.00      0.00       4.0\n",
      "         340       0.00      0.00      0.00       1.0\n",
      "         341       0.00      0.00      0.00       1.0\n",
      "         342       0.00      0.00      0.00       2.0\n",
      "         343       0.00      0.00      0.00       3.0\n",
      "         344       0.00      0.00      0.00       1.0\n",
      "         345       0.00      0.00      0.00       4.0\n",
      "         346       0.00      0.00      0.00       2.0\n",
      "         347       0.00      0.00      0.00       3.0\n",
      "         348       0.00      0.00      0.00       1.0\n",
      "         349       0.00      0.00      0.00       3.0\n",
      "         350       0.00      0.00      0.00       1.0\n",
      "         351       0.00      0.00      0.00       3.0\n",
      "         352       0.00      0.00      0.00       4.0\n",
      "         353       0.00      0.00      0.00       2.0\n",
      "         354       0.00      0.00      0.00       2.0\n",
      "         355       0.00      0.00      0.00       4.0\n",
      "         356       0.00      0.00      0.00       5.0\n",
      "         357       0.00      0.00      0.00       3.0\n",
      "         358       0.00      0.00      0.00       1.0\n",
      "         359       0.00      0.00      0.00       1.0\n",
      "         360       0.00      0.00      0.00       1.0\n",
      "         361       0.00      0.00      0.00       2.0\n",
      "         362       0.00      0.00      0.00       1.0\n",
      "         363       0.00      0.00      0.00       2.0\n",
      "         364       0.00      0.00      0.00       2.0\n",
      "         365       0.00      0.00      0.00       3.0\n",
      "         366       0.00      0.00      0.00       4.0\n",
      "         367       0.00      0.00      0.00       1.0\n",
      "         368       0.00      0.00      0.00       6.0\n",
      "         369       0.00      0.00      0.00       1.0\n",
      "         370       0.00      0.00      0.00       2.0\n",
      "         371       0.00      0.00      0.00       3.0\n",
      "         372       0.00      0.00      0.00       6.0\n",
      "         373       0.00      0.00      0.00       1.0\n",
      "         374       0.00      0.00      0.00       2.0\n",
      "         375       0.00      0.00      0.00       2.0\n",
      "         376       0.00      0.00      0.00       2.0\n",
      "         377       0.00      0.00      0.00       1.0\n",
      "         378       0.00      0.00      0.00       1.0\n",
      "         379       0.00      0.00      0.00       4.0\n",
      "         380       0.00      0.00      0.00       3.0\n",
      "         381       0.00      0.00      0.00       2.0\n",
      "         382       0.00      0.00      0.00       1.0\n",
      "         383       0.00      0.00      0.00       4.0\n",
      "         384       0.00      0.00      0.00       3.0\n",
      "         385       0.00      0.00      0.00       6.0\n",
      "         386       0.00      0.00      0.00       1.0\n",
      "         387       0.00      0.00      0.00       3.0\n",
      "         388       0.00      0.00      0.00       1.0\n",
      "         389       0.00      0.00      0.00       2.0\n",
      "         390       0.00      0.00      0.00       1.0\n",
      "         391       0.00      0.00      0.00       4.0\n",
      "         392       0.00      0.00      0.00       3.0\n",
      "         393       0.00      0.00      0.00       5.0\n",
      "         394       0.00      0.00      0.00       1.0\n",
      "         395       0.00      0.00      0.00       2.0\n",
      "         396       0.00      0.00      0.00       2.0\n",
      "         397       0.00      0.00      0.00       6.0\n",
      "         398       0.00      0.00      0.00       2.0\n",
      "         399       0.00      0.00      0.00       2.0\n",
      "         400       0.00      0.00      0.00       5.0\n",
      "         401       0.00      0.00      0.00       2.0\n",
      "         402       0.00      0.00      0.00       1.0\n",
      "         403       0.00      0.00      0.00       1.0\n",
      "         404       0.00      0.00      0.00       1.0\n",
      "         405       0.00      0.00      0.00       4.0\n",
      "         406       0.00      0.00      0.00       1.0\n",
      "         407       0.00      0.00      0.00       2.0\n",
      "         408       0.00      0.00      0.00       4.0\n",
      "         409       0.00      0.00      0.00       2.0\n",
      "         410       0.00      0.00      0.00       3.0\n",
      "         411       0.00      0.00      0.00       3.0\n",
      "         412       0.00      0.00      0.00       3.0\n",
      "         413       0.00      0.00      0.00       5.0\n",
      "         414       0.00      0.00      0.00       5.0\n",
      "         415       0.00      0.00      0.00       1.0\n",
      "         416       0.00      0.00      0.00       1.0\n",
      "         417       0.00      0.00      0.00       6.0\n",
      "         418       0.00      0.00      0.00       2.0\n",
      "         419       0.00      0.00      0.00       1.0\n",
      "         420       0.00      0.00      0.00       3.0\n",
      "         421       0.00      0.00      0.00       1.0\n",
      "         422       0.00      0.00      0.00       1.0\n",
      "         423       0.00      0.00      0.00       1.0\n",
      "         424       0.00      0.00      0.00       5.0\n",
      "         425       0.00      0.00      0.00       3.0\n",
      "         426       0.00      0.00      0.00       4.0\n",
      "         427       0.00      0.00      0.00       3.0\n",
      "         428       0.00      0.00      0.00       2.0\n",
      "         429       0.00      0.00      0.00       4.0\n",
      "         430       0.00      0.00      0.00       4.0\n",
      "         431       0.00      0.00      0.00       7.0\n",
      "         432       0.00      0.00      0.00       5.0\n",
      "         433       0.00      0.00      0.00    1392.0\n",
      "         435       0.00      0.00      0.00       0.0\n",
      "         442       0.00      0.00      0.00       0.0\n",
      "         447       0.00      0.00      0.00       0.0\n",
      "         459       0.00      0.00      0.00       0.0\n",
      "         536       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    2368.0\n",
      "   macro avg       0.00      0.00      0.00    2368.0\n",
      "weighted avg       0.00      0.00      0.00    2368.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_9596/3514438661.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlab_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Checking performance our model with ROC Score.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlab_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    534\u001b[0m                              \"instead\".format(max_fpr))\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[0;32m    538\u001b[0m                                          multi_class, average, sample_weight)\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(classification_report(lab_enc.fit_transform(y_test), y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(lab_enc.fit_transform(y_test), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe30b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99a17ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 350, 536, 536, 180, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [i for i, x in enumerate(df[df['files_indices']>=32]['class']==0) if x]\n",
    "y_pred[X_test.index.isin(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba7d0a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([536, 536, 536, ..., 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[~X_test.index.isin(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a18cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f2f6345",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 2368 but corresponding boolean dimension is 8043",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_16800/3901874022.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 2368 but corresponding boolean dimension is 8043"
     ]
    }
   ],
   "source": [
    "roc_curve(y_pred[df['class']==0], y_pred[df['class']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d1e197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "2103    1.0\n",
       "2104    1.0\n",
       "2105    1.0\n",
       "2106    1.0\n",
       "2107    1.0\n",
       "Name: 32, Length: 2108, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[df['class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d60de7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>files_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>0.05333</td>\n",
       "      <td>1.10926</td>\n",
       "      <td>0.78470</td>\n",
       "      <td>2.57606</td>\n",
       "      <td>0.65157</td>\n",
       "      <td>9.14565</td>\n",
       "      <td>8.51365</td>\n",
       "      <td>3.53951</td>\n",
       "      <td>4.70391</td>\n",
       "      <td>0.52400</td>\n",
       "      <td>...</td>\n",
       "      <td>56912</td>\n",
       "      <td>27594</td>\n",
       "      <td>29318</td>\n",
       "      <td>31191230.00</td>\n",
       "      <td>5584.91064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>0.08045</td>\n",
       "      <td>0.96369</td>\n",
       "      <td>0.67386</td>\n",
       "      <td>1.47743</td>\n",
       "      <td>0.68072</td>\n",
       "      <td>9.02086</td>\n",
       "      <td>4.88575</td>\n",
       "      <td>3.17193</td>\n",
       "      <td>4.18123</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>...</td>\n",
       "      <td>53463</td>\n",
       "      <td>25007</td>\n",
       "      <td>28456</td>\n",
       "      <td>16596833.00</td>\n",
       "      <td>4073.92114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.76972</td>\n",
       "      <td>0.76791</td>\n",
       "      <td>1.65825</td>\n",
       "      <td>0.71116</td>\n",
       "      <td>8.17358</td>\n",
       "      <td>5.58876</td>\n",
       "      <td>3.23694</td>\n",
       "      <td>4.11483</td>\n",
       "      <td>0.39801</td>\n",
       "      <td>...</td>\n",
       "      <td>58637</td>\n",
       "      <td>23282</td>\n",
       "      <td>35355</td>\n",
       "      <td>33329096.00</td>\n",
       "      <td>5773.13574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>0.04957</td>\n",
       "      <td>1.43643</td>\n",
       "      <td>0.64837</td>\n",
       "      <td>2.04250</td>\n",
       "      <td>0.61214</td>\n",
       "      <td>7.60650</td>\n",
       "      <td>6.70359</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>4.66595</td>\n",
       "      <td>0.65295</td>\n",
       "      <td>...</td>\n",
       "      <td>51738</td>\n",
       "      <td>29318</td>\n",
       "      <td>22420</td>\n",
       "      <td>14905928.00</td>\n",
       "      <td>3860.81958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0.07559</td>\n",
       "      <td>0.75993</td>\n",
       "      <td>0.84205</td>\n",
       "      <td>2.40555</td>\n",
       "      <td>0.71816</td>\n",
       "      <td>9.53440</td>\n",
       "      <td>8.42093</td>\n",
       "      <td>3.41253</td>\n",
       "      <td>4.28450</td>\n",
       "      <td>0.40425</td>\n",
       "      <td>...</td>\n",
       "      <td>56912</td>\n",
       "      <td>16384</td>\n",
       "      <td>40528</td>\n",
       "      <td>58949284.00</td>\n",
       "      <td>7677.84375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.06155</td>\n",
       "      <td>0.69752</td>\n",
       "      <td>0.89054</td>\n",
       "      <td>3.18606</td>\n",
       "      <td>0.74120</td>\n",
       "      <td>7.02580</td>\n",
       "      <td>11.77003</td>\n",
       "      <td>3.62602</td>\n",
       "      <td>4.42574</td>\n",
       "      <td>0.39767</td>\n",
       "      <td>...</td>\n",
       "      <td>10883</td>\n",
       "      <td>2129</td>\n",
       "      <td>8754</td>\n",
       "      <td>3848079.25</td>\n",
       "      <td>1961.65222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.06068</td>\n",
       "      <td>0.75961</td>\n",
       "      <td>0.86736</td>\n",
       "      <td>2.86349</td>\n",
       "      <td>0.71831</td>\n",
       "      <td>7.67092</td>\n",
       "      <td>10.40712</td>\n",
       "      <td>3.60249</td>\n",
       "      <td>4.47293</td>\n",
       "      <td>0.40430</td>\n",
       "      <td>...</td>\n",
       "      <td>10646</td>\n",
       "      <td>1656</td>\n",
       "      <td>8990</td>\n",
       "      <td>3530869.50</td>\n",
       "      <td>1879.06079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.70322</td>\n",
       "      <td>0.85896</td>\n",
       "      <td>2.49303</td>\n",
       "      <td>0.74774</td>\n",
       "      <td>6.01145</td>\n",
       "      <td>9.14703</td>\n",
       "      <td>3.34126</td>\n",
       "      <td>4.10024</td>\n",
       "      <td>0.41432</td>\n",
       "      <td>...</td>\n",
       "      <td>10646</td>\n",
       "      <td>1420</td>\n",
       "      <td>9226</td>\n",
       "      <td>3042845.75</td>\n",
       "      <td>1744.37549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.12647</td>\n",
       "      <td>0.66081</td>\n",
       "      <td>0.88106</td>\n",
       "      <td>2.77796</td>\n",
       "      <td>0.75613</td>\n",
       "      <td>5.16639</td>\n",
       "      <td>10.15986</td>\n",
       "      <td>3.13970</td>\n",
       "      <td>3.91218</td>\n",
       "      <td>0.39423</td>\n",
       "      <td>...</td>\n",
       "      <td>10410</td>\n",
       "      <td>1656</td>\n",
       "      <td>8754</td>\n",
       "      <td>3174905.25</td>\n",
       "      <td>1781.82642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.12322</td>\n",
       "      <td>0.65647</td>\n",
       "      <td>0.87699</td>\n",
       "      <td>2.66837</td>\n",
       "      <td>0.76188</td>\n",
       "      <td>6.34509</td>\n",
       "      <td>9.91083</td>\n",
       "      <td>3.27109</td>\n",
       "      <td>3.97261</td>\n",
       "      <td>0.40030</td>\n",
       "      <td>...</td>\n",
       "      <td>12066</td>\n",
       "      <td>473</td>\n",
       "      <td>11593</td>\n",
       "      <td>5180411.50</td>\n",
       "      <td>2276.05176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4        5         6        7  \\\n",
       "1446  0.05333  1.10926  0.78470  2.57606  0.65157  9.14565   8.51365  3.53951   \n",
       "1447  0.08045  0.96369  0.67386  1.47743  0.68072  9.02086   4.88575  3.17193   \n",
       "1448  0.08401  0.76972  0.76791  1.65825  0.71116  8.17358   5.58876  3.23694   \n",
       "1449  0.04957  1.43643  0.64837  2.04250  0.61214  7.60650   6.70359  3.39093   \n",
       "1450  0.07559  0.75993  0.84205  2.40555  0.71816  9.53440   8.42093  3.41253   \n",
       "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
       "2103  0.06155  0.69752  0.89054  3.18606  0.74120  7.02580  11.77003  3.62602   \n",
       "2104  0.06068  0.75961  0.86736  2.86349  0.71831  7.67092  10.40712  3.60249   \n",
       "2105  0.09644  0.70322  0.85896  2.49303  0.74774  6.01145   9.14703  3.34126   \n",
       "2106  0.12647  0.66081  0.88106  2.77796  0.75613  5.16639  10.15986  3.13970   \n",
       "2107  0.12322  0.65647  0.87699  2.66837  0.76188  6.34509   9.91083  3.27109   \n",
       "\n",
       "            8        9  ...     26     27     28           29          30  31  \\\n",
       "1446  4.70391  0.52400  ...  56912  27594  29318  31191230.00  5584.91064 NaN   \n",
       "1447  4.18123  0.48431  ...  53463  25007  28456  16596833.00  4073.92114 NaN   \n",
       "1448  4.11483  0.39801  ...  58637  23282  35355  33329096.00  5773.13574 NaN   \n",
       "1449  4.66595  0.65295  ...  51738  29318  22420  14905928.00  3860.81958 NaN   \n",
       "1450  4.28450  0.40425  ...  56912  16384  40528  58949284.00  7677.84375 NaN   \n",
       "...       ...      ...  ...    ...    ...    ...          ...         ...  ..   \n",
       "2103  4.42574  0.39767  ...  10883   2129   8754   3848079.25  1961.65222 NaN   \n",
       "2104  4.47293  0.40430  ...  10646   1656   8990   3530869.50  1879.06079 NaN   \n",
       "2105  4.10024  0.41432  ...  10646   1420   9226   3042845.75  1744.37549 NaN   \n",
       "2106  3.91218  0.39423  ...  10410   1656   8754   3174905.25  1781.82642 NaN   \n",
       "2107  3.97261  0.40030  ...  12066    473  11593   5180411.50  2276.05176 NaN   \n",
       "\n",
       "       32  \\\n",
       "1446  1.0   \n",
       "1447  1.0   \n",
       "1448  1.0   \n",
       "1449  1.0   \n",
       "1450  1.0   \n",
       "...   ...   \n",
       "2103  1.0   \n",
       "2104  1.0   \n",
       "2105  1.0   \n",
       "2106  1.0   \n",
       "2107  1.0   \n",
       "\n",
       "                                                                                                   file_name  \\\n",
       "1446  VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219   \n",
       "1447  VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219   \n",
       "1448  VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219   \n",
       "1449  VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219   \n",
       "1450  VVG15051946__20180724__11069__CT__HEAD__0004__brain 1 mm_1.2.840.113704.1.111.5240.1532410506.8795_219   \n",
       "...                                                                                                      ...   \n",
       "2103  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2104  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2105  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2106  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "2107  ZSA29101953__20170511__6862__CT__HEAD__0002__brain 1 mm_1.2.840.113704.1.111.4524.1494468681.17959_237   \n",
       "\n",
       "      class  files_indices  \n",
       "1446      0             32  \n",
       "1447      0             32  \n",
       "1448      0             32  \n",
       "1449      0             32  \n",
       "1450      0             32  \n",
       "...     ...            ...  \n",
       "2103      0             45  \n",
       "2104      0             45  \n",
       "2105      0             45  \n",
       "2106      0             45  \n",
       "2107      0             45  \n",
       "\n",
       "[662 rows x 36 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['files_indices']>=32) & (df['class']==0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75e640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "490a41b8",
   "metadata": {},
   "source": [
    "# Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b8883a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a248c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.cluster import SpectralClustering\n",
    "sc = SpectralClustering(n_clusters=2)\n",
    "\n",
    "def clus_en_matrix(X, L, K):\n",
    "    n = len(X)\n",
    "    c_mem = np.zeros((n,L), dtype=int)\n",
    "    A_m = [None]*L\n",
    "    K_l = np.zeros(L, dtype=int)\n",
    "    D = csr_matrix((n,n), dtype='int')\n",
    "#     opts = ...\n",
    "    for l in range(L):\n",
    "        C = sc.fit(X)\n",
    "        c_mem[:,l] = C.labels_\n",
    "        \n",
    "    for l in range(L):\n",
    "        A_m[l] = csr_matrix((np.ones(n, dtype='int'),\n",
    "                    (np.arange(n),c_mem[:,l])), shape=(n,K+l))\n",
    "        \n",
    "    A = A_m[1]\n",
    "    for l in range(1,L):\n",
    "        A = hstack([A, A_m[l]])\n",
    "    \n",
    "    A = np.sqrt(1/L)*A\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(lab_enc.fit_transform(y_test), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01457a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import SpectralClustering\n",
    "knn = KNeighborsClassifier()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 100))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False, verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, y_train_encoded)\n",
    "\n",
    "n_clusters=2,\n",
    "        assign_labels='discretize',\n",
    "        random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c29d0fc2",
   "metadata": {},
   "source": [
    "# OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5447077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 204, 234, ..., 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ValueError: Unknown label type: 'continuous'\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2104b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 29 candidates, totalling 290 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 672, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 672, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 672, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_5692/3780245691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# fitting the model for grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         (self.ordering_, self.core_distances_, self.reachability_,\n\u001b[1;32m--> 254\u001b[1;33m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessor_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_optics_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m              \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m              \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001b[0m in \u001b[0;36mcompute_optics_graph\u001b[1;34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;31m# the original OPTICS that only used epsilon range queries.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;31m# TODO: handle working_memory somehow?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m     core_distances_ = _compute_core_distances_(X=X, neighbors=nbrs,\n\u001b[0m\u001b[0;32m    472\u001b[0m                                                \u001b[0mmin_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                                                working_memory=None)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001b[0m in \u001b[0;36m_compute_core_distances_\u001b[1;34m(X, neighbors, min_samples, working_memory)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_n_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         core_distances[sl] = neighbors.kneighbors(\n\u001b[0m\u001b[0;32m    337\u001b[0m             X[sl], min_samples)[0][:, -1]\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcore_distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         neigh_ind = neigh_ind[\n\u001b[1;32m--> 586\u001b[1;33m             sample_range, np.argsort(dist[sample_range, neigh_ind])]\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \"\"\"\n\u001b[1;32m-> 1112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argsort'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "opt = OPTICS()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 30))\n",
    "param_grid = dict(min_samples=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(opt, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f04d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44512896",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e04aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 204, 234, ..., 536, 536, 536], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ValueError: Unknown label type: 'continuous'\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24107bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "             (1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,), (12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,)\n",
    "             ]\n",
    "        }\n",
    "       ]\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid, cv=3,\n",
    "                           scoring='accuracy')\n",
    "clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b14b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 99 candidates, totalling 990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 100))\n",
    "param_grid = dict(max_iter=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(mlp, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22339ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4644f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1acfc19",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "181168a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_17092/2810093245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlogreg_cv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlogreg_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tuned hpyerparameters :(best parameters) \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogreg_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1356\u001b[0m                               \u001b[1;34m\" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m                               \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n\u001b[1;32m-> 1358\u001b[1;33m             self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[0;32m   1359\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[0;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-4, 4, 50), \"penalty\":[\"l1\",\"l2\"], \"solver\":['liblinear', 'saga']}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train_encoded)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4811993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d52a9ef",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a38fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb3dadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kunasyl.DESKTOP-N9JUTUQ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1024),\n",
       "             param_grid={'ccp_alpha': [0.1, 0.01, 0.001],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 6, 7, 8, 9],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2']},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#For work encode categorical atrubuts\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#For do a best a work flow\n",
    "from sklearn.pipeline import Pipeline\n",
    "#Missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 6, 7, 8, 9],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "tree_clas = DecisionTreeClassifier(random_state=1024)\n",
    "grid_search = GridSearchCV(estimator=tree_clas, param_grid=param_grid, cv=5, verbose=True)\n",
    "grid_search.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d83dbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.1, max_depth=5, max_features='auto',\n",
       "                       random_state=1024)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b47d9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clas = DecisionTreeClassifier(ccp_alpha=0.1, class_weight=None, criterion='entropy',\n",
    "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=1024, splitter='best')\n",
    "tree_clas.fit(X_train, y_train_encoded)\n",
    "y_predict = tree_clas.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cffca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec0acaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    1],\n",
       "       [   0,    0,    0, ...,    0,    0,    1],\n",
       "       [   0,    0,    0, ...,    0,    0,    1],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    5],\n",
       "       [   0,    0,    0, ...,    0,    0, 1392],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lab_enc.fit_transform(y_test), y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6f9a03b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_17092/1938448332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cf007c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KUNASY~1.DES\\AppData\\Local\\Temp/ipykernel_17092/2708787696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "print(\"accuracy :\",final_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
